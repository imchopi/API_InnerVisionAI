## 1. Justificaci√≥n y descripci√≥n del proyecto.
## 2. Obtenci√≥n de datos. Se debe especificar la fuente de los datos. Se indicar√° por qu√© medios se han obtenido (encuestas, sensores, scrapping, etc.). Los datos se deben cargar en una estructura que permita su posterior manipulaci√≥n y uso.
## 3. Limpieza de datos (eliminaci√≥n de nulos y datos err√≥neos, etc.). Descripci√≥n de los datos. Se debe dar una descripci√≥n completa de los datos indicando qu√© significa cada uno de los atributos.
## 4. Exploraci√≥n y visualizaci√≥n de los datos. Se realizar√° un estudio de los datos buscando correlaciones, mostrando gr√°ficas de diferente tipolog√≠a, observando si hay valores nulos, etc.
## 5. Preparaci√≥n de los datos para los algoritmos de Machine Learning. Se deben tratar los datos (limpiando, escalando, separando y todo lo que sea necesario) de tal forma que queden listos para entrenar el modelo.

## 6. Entrenamiento del modelo y comprobaci√≥n del rendimiento. Se entrenar√°n uno o varios modelos, comprobando en cada caso el rendimiento que ofrecen mediante las apropiadas medidas de error y/o acierto.

### 6.1 Proceso de Fine-Tuning con YOLOv5

El objetivo del fine-tuning es adaptar un modelo preentrenado de YOLOv5 (yolov5nu.pt) a nuestro dataset, mejorando su capacidad de detecci√≥n en nuestro caso de uso espec√≠fico.

### üìÇ 6.1.1 Preparaci√≥n del Dataset
Para entrenar el modelo, primero preparamos los datos siguiendo los pasos detallados a continuaci√≥n:

1Ô∏è‚É£ Obtenci√≥n del Dataset

Realizamos scraping de im√°genes, almacen√°ndolas en un archivo CSV en formato base64.

üìå Ejemplo de archivo:
![image](https://github.com/user-attachments/assets/6803008a-0ca4-4ad6-830b-18efb486ba31)

---

2Ô∏è‚É£ Conversi√≥n de Im√°genes

Como las im√°genes estaban almacenadas en formato base64, era necesario decodificarlas para poder usarlas en el entrenamiento.

Utilizamos el siguiente script en Python para convertir las im√°genes de base64 a `.jpg`:

![image](https://github.com/user-attachments/assets/58af828c-a9dc-40a4-9005-2d6db3b7bb56)

---

3Ô∏è‚É£ Etiquetado de Im√°genes

Para entrenar un modelo de detecci√≥n de objetos, cada imagen necesita etiquetas con las coordenadas de los objetos. Utilizamos **Roboflow**, una plataforma que permite:

- ‚úÖ Subir im√°genes.
- ‚úÖ Etiquetar im√°genes manualmente o autom√°ticamente con herramientas de anotaci√≥n.
- ‚úÖ Convertir el dataset a formatos compatibles con modelos de detecci√≥n como YOLOv5.
- ‚úÖ Dividir los datos en conjuntos de entrenamiento, validaci√≥n y prueba.

Nuestro objetivo fue **etiquetar autom√°ticamente** im√°genes del dataset para detectar objetos de inter√©s y exportarlas en formato YOLOv5.

üîπ Creaci√≥n de un Proyecto en Roboflow

- Asignamos un nombre al proyecto, por ejemplo: cupboard_detection.
- Seleccionamos el tipo de modelo: Object Detection (YOLOv5, COCO, etc.)

![image](https://github.com/user-attachments/assets/6ad1ed78-265d-44b6-8ecb-ff13b256031b)
  

üîπ Subida de Im√°genes al Proyecto

![image](https://github.com/user-attachments/assets/5c00338e-e366-49b7-b870-caab13064313)

üîπ Etiquetado Autom√°tico de Objetos

Dado que Roboflow cuenta con herramientas de etiquetado autom√°tico, utilizamos esta opci√≥n para generar anotaciones sin intervenci√≥n manual.

![image](https://github.com/user-attachments/assets/65260858-f3dd-4f6e-b690-78e095ef2e20)

Si bien el etiquetado autom√°tico es preciso, verificamos que las anotaciones fueran correctas.

![image](https://github.com/user-attachments/assets/b50e683b-e12b-4f62-906e-a672ed6310d8)

En caso de errores, ajustamos manualmente las etiquetas antes de continuar para completar el proceso.

![image](https://github.com/user-attachments/assets/ebea7738-f6de-4def-853f-dd361ac78e29)

Despu√©s de la comprobaci√≥n a√±adimos las etiquetas aprobadas.

![image](https://github.com/user-attachments/assets/faf2c310-4d9d-47ba-8a08-9e818f91ae73)



üîπ Exportaci√≥n del Dataset en Formato YOLOv5

Para utilizar las im√°genes etiquetadas en el entrenamiento del modelo, exportamos el dataset en formato YOLOv5.

Roboflow nos permite dividir el dataset en tres subconjuntos:
- 80% para entrenamiento (train)
- 10% para validaci√≥n (valid)
- 10% para prueba (test)

![image](https://github.com/user-attachments/assets/9a021657-f59a-4b1c-bac5-f258790e0bf2)

En la secci√≥n de exportaci√≥n, seleccionamos YOLOv5 como formato de salida y descargamos un archivo ZIP.

![image](https://github.com/user-attachments/assets/a4fd3ee4-1efb-4581-8b08-c9d18a9aefb9)

El archivo ZIP tiene la siguiente estructura:

```
/dataset
‚îÇ‚îÄ‚îÄ test/    # 10% de im√°genes para prueba
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/   
‚îÇ
‚îÇ‚îÄ‚îÄ train/   # 80% de im√°genes para entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
|
‚îÇ‚îÄ‚îÄ valid/   # 10% de im√°genes para validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
‚îÇ
‚îÇ‚îÄ‚îÄ data.yaml    # Archivo de configuraci√≥n del dataset
```

En el directorio `labels` obtenemos archivos .txt con las coordenadas de los objetos.


### üõ† 6.1.2 Entrenamiento del Modelo

Para el entrenamiento utilizamos el modelo preentrenado **yolov5nu.pt**. Ejecutamos el proceso en Google Colab con GPU habilitada para acelerar el c√≥mputo. Clonamos el repositorio de YOLOv5. Usamos los siguientes par√°metros en el script de entrenamiento:

```python
!python train.py \
  --weights /content/drive/MyDrive/Models/yolov5nu.pt \
  --data /content/drive/MyDrive/YOLO_Dataset/data.yaml \
  --epochs 50 \
  --batch-size 16 \
  --imgsz 640 \
  --optimizer SGD \
  --device 0
```

Sin embargo, durante la ejecuci√≥n del entrenamiento encontramos errores relacionados con la configuraci√≥n de los anchors en el modelo. El siguiente es un ejemplo de los errores que recibimos:

```
RuntimeError: shape '[3, -1, 2]' is invalid for input of size 3
```

Este error sugiere que los anchors definidos en el modelo no se ajustaban correctamente al n√∫mero de clases u otras dimensiones esperadas. Intentamos modificar la configuraci√≥n, pero el problema persisti√≥.

---

‚ö†Ô∏è Problemas Encontrados y Conclusi√≥n

No logramos completar el fine-tuning debido a erroresencontrados. Las posibles causas incluyen:

1. **Incompatibilidad en los anchors**: La configuraci√≥n de los anchors puede no haber sido adecuada para nuestro dataset. 
2. **Formato incorrecto en el archivo data.yaml**: Es posible que las clases o los par√°metros en el archivo no estuvieran correctamente definidos.
3. **Modelo preentrenado incompatible**: Puede que el modelo **yolov5nu.pt** no estuviera configurado correctamente para ser reutilizado con nuevos datos.

Para solucionar estos problemas, proponemos:
- Revisar el formato de **data.yaml** y asegurarnos de que est√° bien definido.
- Ajustar los anchors manualmente o permitir que YOLO los recalibre autom√°ticamente.
- Probar con otro modelo preentrenado de YOLOv5 para verificar compatibilidad.

A pesar de las dificultades, este proceso nos permiti√≥ comprender mejor el flujo de trabajo de YOLOv5 y los retos asociados a la personalizaci√≥n de modelos de detecci√≥n de objetos. Con algunos ajustes, creemos que podemos completar con √©xito el fine-tuning en futuras iteraciones.



## 7. Se tiene que incluir alguna de las t√©cnicas estudiadas en el tema de Procesamiento de Lenguaje Natural: expresiones regulares, tokenizaci√≥n, generaci√≥n de texto, an√°lisis de sentimientos, etc.

## 8. Desarrollo de la Aplicaci√≥n Web

Nuestra aplicaci√≥n web ha sido desarrollada utilizando **React** e **Ionic** con **TypeScript**, proporcionando una experiencia moderna y responsiva. A continuaci√≥n, describimos los principales componentes de la web junto con capturas del c√≥digo y la interfaz.

### 8.1 Estructura del Proyecto

El proyecto se organiza en distintos componentes de React y p√°ginas espec√≠ficas para cada funcionalidad. Nuestra estructura principal incluye:
- **Home.tsx** (P√°gina de inicio)
- **Model.tsx** (M√≥dulo de detecci√≥n de objetos)
- **AboutUs.tsx** (Informaci√≥n del equipo)
- **Chatbot.tsx** (Asistente virtual basado en IA)

Con esta organizaci√≥n permitimos una estructura modular y escalable. üöÄ

### 8.2 Inicio (Home.tsx)

Nuestra p√°gina principal (**Home.tsx**) presenta el proyecto y enlaza a su repositorio en GitHub. Hemos utilizado iconos para mejorar la accesibilidad visual.

#### ¬øQu√© hace este archivo?
- Muestra el dise√±o principal: Incluimos el encabezado, el contenido y cualquier elemento visual que queramos resaltar.
- Carga datos si es necesario: Dependiendo de lo que queremos mostrar, aqu√≠ podemos traer informaci√≥n desde una API o una base de datos.
- Facilita la navegaci√≥n: Agregamos enlaces o botones para que los usuarios puedan moverse dentro de nuestra aplicaci√≥n.
  
---

#### 8.2.1 Importaci√≥n de librer√≠as y estilos
El archivo `Home.tsx` es un componente de React que utiliza Ionic y otros elementos para la estructura y dise√±o de la pantalla principal de la aplicaci√≥n.

üìå C√≥digo de importaci√≥n:
![image](https://github.com/user-attachments/assets/b3ce7a56-9c89-4614-93ee-706c37b11121)

---

#### 8.2.2 Contenido de la p√°gina
En la secci√≥n principal de la pantalla, mostramos el t√≠tulo del proyecto junto con una breve descripci√≥n para que los usuarios comprendan su prop√≥sito de inmediato. Adem√°s, proporcionamos enlaces directos a los repositorios de GitHub, tanto para la web como para la API, con iconos interactivos que facilitan el acceso.

üìå C√≥digo del contenido:
![image](https://github.com/user-attachments/assets/1d891c5d-278b-42b3-8b11-5adc13391e66)

---

#### 8.2.3 Estilos Aplicados
En `Home.css`, definimos estilos para mejorar la apariencia del componente. 

üìå Ejemplo de dise√±o:

![image](https://github.com/user-attachments/assets/2b9051a9-4ea8-4f39-bdbf-de611e44f181)

Con estos estilos nos aseguramos que la p√°gina tenga un dise√±o centrado y est√©tico.


‚ú® **Vista de la p√°gina de inicio:**  

![image](https://github.com/user-attachments/assets/a850f36f-605a-406a-a75b-50b4e671ce34)


Esta p√°gina brinda una bienvenida clara y acceso directo a la informaci√≥n clave del proyecto. üöÄ

## 8.3 Modelo de Detecci√≥n de Objetos (Model.tsx)

En esta p√°gina implementamos la detecci√≥n de objetos en tiempo real utilizando la c√°mara del dispositivo. Para ello, hacemos uso de WebSockets para enviar frames al backend y recibir las detecciones procesadas.

#### ¬øQu√© hace este archivo?
- Captura video en tiempo real desde la c√°mara del dispositivo. El c√≥digo a continuaci√≥n solicita permisos para acceder a la c√°mara del dispositivo y captura el video en tiempo real:
  
  ![image](https://github.com/user-attachments/assets/9d704801-afd2-4f15-8cb7-8563a47fdeb5)

- Env√≠a frames al backend. Usa WebSockets para enviar im√°genes a la API, donde se realiza la detecci√≥n de objetos.

  ![image](https://github.com/user-attachments/assets/3045fff8-ff73-4c49-b901-24192edad290)

  
- Recibe y dibuja detecciones. Recibe los resultados del backend y los dibuja sobre el video en un canvas.

  ![image](https://github.com/user-attachments/assets/aa6c6931-02fe-444d-83f4-0db89417b673)

---

#### 8.3.1 Importaci√≥n de librer√≠as y estilos
El archivo Model.tsx importa las siguientes librer√≠as:

- react, useEffect, useRef: Para gestionar el ciclo de vida del componente y referencias.
- socket.io-client: Para la comunicaci√≥n en tiempo real con el backend.
- @ionic/react: Para la estructura de la p√°gina en Ionic.
- @capacitor/core y @capacitor/status-bar: Para ajustar la interfaz en dispositivos m√≥viles.

üìå C√≥digo de importaci√≥n:
![image](https://github.com/user-attachments/assets/44c13030-c11c-450b-8eff-bf19317438da)

---

#### 8.3.2 Contenido de la p√°gina
Esta secci√≥n estructura la interfaz del m√≥dulo:

- Video en vivo: Capturamos la imagen de la c√°mara.
- Canvas de detecciones: Dibujamos los resultados del modelo de IA sobre el video.

üìå C√≥digo del contenido:
![image](https://github.com/user-attachments/assets/a9428b16-d8ba-474a-9211-cdd2a1f4d686)

---

#### 8.3.3 Comunicaci√≥n con el Backend

Conexi√≥n al Backend (A nivel local)
![image](https://github.com/user-attachments/assets/9f55390b-f505-409d-a544-9972425c4e85)

Aqu√≠ se establece la conexi√≥n con el backend en el puerto 5000.

Cuando el backend detecta objetos en el frame enviado, devuelve las coordenadas y la confianza del modelo. Este c√≥digo se encarga de dibujar los resultados sobre el video:

![image](https://github.com/user-attachments/assets/61bd5e5d-8bb5-4451-8c40-a219badb81d9)

Desconecta el socket cuando el usuario sale de la p√°gina:

![image](https://github.com/user-attachments/assets/c6493fce-0297-4b97-a311-39f34df48f0a)

---

#### 8.3.4 Estilos Aplicados
En Model.css, definimos estilos para:

Centrar el video en pantalla.
Ajustar el tama√±o del video y el canvas.
Aplicar un fondo con degradado.

üìå Ejemplo de dise√±o:
![image](https://github.com/user-attachments/assets/c44fcc65-8273-48ec-b1da-ffd645ccf3e7)


‚ú® **Vista del modelo de detecci√≥n de objetos:**

[Imagen del modelo funcionando]

Con esta implementaci√≥n logramos un procesamiento √°gil y preciso, permitiendo a los usuarios identificar objetos en tiempo real de manera intuitiva y eficaz. üéØ

## 8.4 Informaci√≥n del Equipo (AboutUs.tsx)

En esta p√°gina mostramos a los integrantes del equipo de desarrollo. En la p√°gina se puede visualizar una lista de miembros, su rol, su formaci√≥n y enlaces a sus perfiles de GitHub y LinkedIn.

‚ú® **Vista de la p√°gina de Informaci√≥n del Equipo:**

![image](https://github.com/user-attachments/assets/e2236a86-5f5f-44dc-82c4-b8aa7872afaa)


## 8.5 Chatbot (Chatbot.tsx)

En esta p√°gina implementamos un chatbot interactivo que permite a los usuarios realizar preguntas. Utilizamos un backend en Node.js para procesar las consultas y devolver respuestas din√°micas.

### ¬øQu√© hace este archivo?
- **Muestra un chatbot en la aplicaci√≥n.**
- **Permite la interacci√≥n con el usuario.** El usuario puede escribir preguntas y recibir respuestas en tiempo real.
- **Env√≠a consultas a un backend en Node.js.** Se conecta a un servidor en `http://localhost:5000/chat` para procesar los mensajes.
- **Formatea las respuestas.** Convierte ciertos elementos de texto como negritas y listas en formato HTML para mejorar la legibilidad.

---

### 8.5.1 Importaci√≥n de librer√≠as y estilos
El archivo `Chatbot.tsx` importa las siguientes librer√≠as:

- **react, useState**: Para gestionar el estado del chatbot y los mensajes.
- **axios**: Para enviar solicitudes HTTP al backend.
- **@ionic/react**: Para la estructura de la p√°gina.
- **Footer**: Componente reutilizable para el pie de p√°gina.
- **Chatbot.css**: Archivo de estilos para la apariencia del chatbot.

üìå **C√≥digo de importaci√≥n:**
![image](https://github.com/user-attachments/assets/8822090b-325f-4af6-aa1f-72307de3ce1f)


### 8.5.2 Estado y manejo de mensajes
Almacenamos los mensajes en un array gestionado con `useState`. Inicialmente, contiene un mensaje de bienvenida del bot:

üìå **C√≥digo de inicializaci√≥n:**
![image](https://github.com/user-attachments/assets/bf0786c2-d521-4084-a8a0-e469a4a0aa52)
![image](https://github.com/user-attachments/assets/59699bd8-f7bf-437c-bffb-d92c8e92b76d)


El usuario puede escribir un mensaje y enviarlo con `sendMessage()`, que realiza las siguientes acciones:
1. Agrega el mensaje del usuario al estado.
2. Env√≠a la consulta al backend mediante una petici√≥n `POST`.
3. Recibe la respuesta del servidor y la formatea.
4. Agrega la respuesta del chatbot a la conversaci√≥n.
5. Limpia el input despu√©s de enviar el mensaje.

üìå **C√≥digo de env√≠o de mensajes:**
![image](https://github.com/user-attachments/assets/f6eabbe7-1417-42dd-88b0-25fa0b26bf11)


---

### 8.5.3 Renderizado del Chatbot

El chatbot se compone de:
- Un **contenedor de mensajes**, donde se muestran las interacciones previas.
- Un **input de texto** para que el usuario escriba su mensaje.
- Un **bot√≥n de env√≠o** para enviar mensajes manualmente.
- La posibilidad de presionar **Enter** para enviar el mensaje.

üìå **C√≥digo del renderizado:**
![image](https://github.com/user-attachments/assets/ef0402ba-5a17-42e8-8ef4-591904aab9c8)


---

### 8.5.4 Formateo de respuestas

Para mejorar la presentaci√≥n de las respuestas, convertimos ciertos elementos a formato HTML:
- **Negritas**: `**texto**` ‚Üí `<strong>texto</strong>`
- **Saltos de l√≠nea**: `\n` ‚Üí `<br>`
- **Listas numeradas**: `1. Texto` ‚Üí `‚Ä¢ Texto`

üìå **C√≥digo de formateo:**
![image](https://github.com/user-attachments/assets/ac19de25-1edd-4c50-b5e9-ac02fcf076a0)



---

‚ú® **Vista del chatbot funcionando:**

[Imagen del chatbot]

Con esta implementaci√≥n ofrecemos una experiencia fluida y responsiva, permitiendo a los usuarios interactuar con el asistente virtual de manera sencilla y eficiente. üöÄ

