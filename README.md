## 1. Justificaci√≥n y descripci√≥n del proyecto.
**Desarrolladores**
- Alejandro Fern√°ndez Barrionuevo
- Adri√°n Perogil Fern√°ndez
- Carlos

**T√≠tulo**
InnerVisionAI

**Descripci√≥n**
Un proyecto basado en detecci√≥n de obst√°culos donde, gracias al uso de YOLO, podemos detectar con una c√°mara todo tipo de objetos en la vida real.

Su uso escalable y la intenci√≥n con la que se hizo este proyecto fue para ayudar a personas con discapacidades visuales que mediante audio, guiara a las personas
y pudiera recibir un feedback en todo momento, as√≠ pudiendo caminar con mayor comodidad y seguridad. 

Como el tiempo que tuvimos era limitado y era muy ambicioso, nos vimos en la obligaci√≥n de pensar "niveles" para empezar con algo b√°sico hasta llegar al target.

**C√≥digo fuente**
[WEB](https://github.com/imchopi/InnerVisionAI/tree/feature_alex)
[API](https://github.com/imchopi/API_InnerVisionAI)

**Presentaci√≥n en formato PDF**
Pr√≥ximamente...

**Enlace a la aplicaci√≥n web**
[P√°gina Web](https://innervisionai.netlify.app/home)

**Recursos utilizados**
- Jira

**V√≠deo**
Pr√≥ximamente...

**Porcentaje que le corresponde a cada miembro del trabajo realizado de dicho proyecto.**
Alejandro Fern√°ndez Barrionuevo ()
Adri√°n Perogil Fern√°ndez ()
Carlos ()

## 2. Obtenci√≥n de datos. Se debe especificar la fuente de los datos. Se indicar√° por qu√© medios se han obtenido (encuestas, sensores, scrapping, etc.). Los datos se deben cargar en una estructura que permita su posterior manipulaci√≥n y uso.
## 3. Limpieza de datos (eliminaci√≥n de nulos y datos err√≥neos, etc.). Descripci√≥n de los datos. Se debe dar una descripci√≥n completa de los datos indicando qu√© significa cada uno de los atributos.
## 4. Exploraci√≥n y visualizaci√≥n de los datos. Se realizar√° un estudio de los datos buscando correlaciones, mostrando gr√°ficas de diferente tipolog√≠a, observando si hay valores nulos, etc.

## 5. Preparaci√≥n de los datos para los algoritmos de Machine Learning. Se deben tratar los datos (limpiando, escalando, separando y todo lo que sea necesario) de tal forma que queden listos para entrenar el modelo.
### 5.1 Proceso de Fine-Tuning con YOLOv5

El objetivo del fine-tuning es adaptar un modelo preentrenado de YOLOv5 (yolov5nu.pt) a nuestro dataset, mejorando su capacidad de detecci√≥n en nuestro caso de uso espec√≠fico.

### üìÇ 5.1.1 Preparaci√≥n del Dataset
Para entrenar el modelo, primero preparamos los datos siguiendo los pasos detallados a continuaci√≥n:

1Ô∏è‚É£ Obtenci√≥n del Dataset

Realizamos scraping de im√°genes, almacen√°ndolas en un archivo CSV en formato base64.

üìå Ejemplo de archivo:
![image](https://github.com/user-attachments/assets/6803008a-0ca4-4ad6-830b-18efb486ba31)

---

2Ô∏è‚É£ Conversi√≥n de Im√°genes

Como las im√°genes estaban almacenadas en formato base64, era necesario decodificarlas para poder usarlas en el entrenamiento.

Utilizamos el siguiente script en Python para convertir las im√°genes de base64 a `.jpg`:

![image](https://github.com/user-attachments/assets/58af828c-a9dc-40a4-9005-2d6db3b7bb56)

---

3Ô∏è‚É£ Etiquetado de Im√°genes

Para entrenar un modelo de detecci√≥n de objetos, cada imagen necesita etiquetas con las coordenadas de los objetos. Utilizamos **Roboflow**, una plataforma que permite:

- ‚úÖ Subir im√°genes.
- ‚úÖ Etiquetar im√°genes manualmente o autom√°ticamente con herramientas de anotaci√≥n.
- ‚úÖ Convertir el dataset a formatos compatibles con modelos de detecci√≥n como YOLOv5.
- ‚úÖ Dividir los datos en conjuntos de entrenamiento, validaci√≥n y prueba.

Nuestro objetivo fue **etiquetar autom√°ticamente** im√°genes del dataset para detectar objetos de inter√©s y exportarlas en formato YOLOv5.

üîπ Creaci√≥n de un Proyecto en Roboflow

- Asignamos un nombre al proyecto, por ejemplo: cupboard_detection.
- Seleccionamos el tipo de modelo: Object Detection (YOLOv5, COCO, etc.)

![image](https://github.com/user-attachments/assets/6ad1ed78-265d-44b6-8ecb-ff13b256031b)
  

üîπ Subida de Im√°genes al Proyecto

![image](https://github.com/user-attachments/assets/5c00338e-e366-49b7-b870-caab13064313)

üîπ Etiquetado Autom√°tico de Objetos

Dado que Roboflow cuenta con herramientas de etiquetado autom√°tico, utilizamos esta opci√≥n para generar anotaciones sin intervenci√≥n manual.

![image](https://github.com/user-attachments/assets/65260858-f3dd-4f6e-b690-78e095ef2e20)

Si bien el etiquetado autom√°tico es preciso, verificamos que las anotaciones fueran correctas.

![image](https://github.com/user-attachments/assets/b50e683b-e12b-4f62-906e-a672ed6310d8)

En caso de errores, ajustamos manualmente las etiquetas antes de continuar para completar el proceso.

![image](https://github.com/user-attachments/assets/ebea7738-f6de-4def-853f-dd361ac78e29)

Despu√©s de la comprobaci√≥n a√±adimos las etiquetas aprobadas.

![image](https://github.com/user-attachments/assets/faf2c310-4d9d-47ba-8a08-9e818f91ae73)



üîπ Exportaci√≥n del Dataset en Formato YOLOv5

Para utilizar las im√°genes etiquetadas en el entrenamiento del modelo, exportamos el dataset en formato YOLOv5.

Roboflow nos permite dividir el dataset en tres subconjuntos:
- 80% para entrenamiento (train)
- 10% para validaci√≥n (valid)
- 10% para prueba (test)

![image](https://github.com/user-attachments/assets/9a021657-f59a-4b1c-bac5-f258790e0bf2)

En la secci√≥n de exportaci√≥n, seleccionamos YOLOv5 como formato de salida y descargamos un archivo ZIP.

![image](https://github.com/user-attachments/assets/a4fd3ee4-1efb-4581-8b08-c9d18a9aefb9)

El archivo ZIP tiene la siguiente estructura:

```
/dataset
‚îÇ‚îÄ‚îÄ test/    # 10% de im√°genes para prueba
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/   
‚îÇ
‚îÇ‚îÄ‚îÄ train/   # 80% de im√°genes para entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
|
‚îÇ‚îÄ‚îÄ valid/   # 10% de im√°genes para validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ images/
‚îÇ   ‚îú‚îÄ‚îÄ labels/
‚îÇ
‚îÇ‚îÄ‚îÄ data.yaml    # Archivo de configuraci√≥n del dataset
```

En el directorio `labels` obtenemos archivos .txt con las coordenadas de los objetos.


### üõ† 5.1.2 Entrenamiento del Modelo

Para el entrenamiento utilizamos el modelo preentrenado **yolov5nu.pt**. Ejecutamos el proceso en Google Colab con GPU habilitada para acelerar el c√≥mputo. Clonamos el repositorio de YOLOv5. Usamos los siguientes par√°metros en el script de entrenamiento:

```python
!python train.py \
  --weights /content/drive/MyDrive/Models/yolov5nu.pt \
  --data /content/drive/MyDrive/YOLO_Dataset/data.yaml \
  --epochs 50 \
  --batch-size 16 \
  --imgsz 640 \
  --optimizer SGD \
  --device 0
```

Sin embargo, durante la ejecuci√≥n del entrenamiento encontramos errores relacionados con la configuraci√≥n de los anchors en el modelo. El siguiente es un ejemplo de los errores que recibimos:

```
RuntimeError: shape '[3, -1, 2]' is invalid for input of size 3
```

Este error sugiere que los anchors definidos en el modelo no se ajustaban correctamente al n√∫mero de clases u otras dimensiones esperadas. Intentamos modificar la configuraci√≥n, pero el problema persisti√≥.

---

‚ö†Ô∏è Problemas Encontrados y Conclusi√≥n

No logramos completar el fine-tuning debido a erroresencontrados. Las posibles causas incluyen:

1. **Incompatibilidad en los anchors**: La configuraci√≥n de los anchors puede no haber sido adecuada para nuestro dataset. 
2. **Formato incorrecto en el archivo data.yaml**: Es posible que las clases o los par√°metros en el archivo no estuvieran correctamente definidos.
3. **Modelo preentrenado incompatible**: Puede que el modelo **yolov5nu.pt** no estuviera configurado correctamente para ser reutilizado con nuevos datos.

Para solucionar estos problemas, proponemos:
- Revisar el formato de **data.yaml** y asegurarnos de que est√° bien definido.
- Ajustar los anchors manualmente o permitir que YOLO los recalibre autom√°ticamente.
- Probar con otro modelo preentrenado de YOLOv5 para verificar compatibilidad.

A pesar de las dificultades, este proceso nos permiti√≥ comprender mejor el flujo de trabajo de YOLOv5 y los retos asociados a la personalizaci√≥n de modelos de detecci√≥n de objetos. Con algunos ajustes, creemos que podemos completar con √©xito el fine-tuning en futuras iteraciones.


## 6. Entrenamiento del modelo y comprobaci√≥n del rendimiento. Se entrenar√°n uno o varios modelos, comprobando en cada caso el rendimiento que ofrecen mediante las apropiadas medidas de error y/o acierto.

### 6.1 Uso de YOLOv5 de Ultralytics y Chatbot personalizado

En este apartado, se describe el proceso de implementaci√≥n de YOLOv5 de Ultralytics, desde la configuraci√≥n del entorno hasta la integraci√≥n con una API en Flask y un frontend en React. El objetivo es demostrar c√≥mo este modelo puede ser utilizado para detectar objetos en tiempo real, enviando los resultados de las detecciones a una interfaz gr√°fica que permite visualizar las predicciones de manera intuitiva. 
Adem√°s, se aborda la importancia de optimizar el flujo de trabajo para garantizar un rendimiento √≥ptimo, especialmente como tratar el funcionamiento con recursos gratuitos y el limite que establece Netlify y nuestra API con Flask en local.

Tambi√©n ideamos un chatbot con una API-KEY de OpenAI, donde con base en nuestro README.md, procese y responda preguntas y cuestiones sobre nuestro proyecto debido a, que nuestro readme va a ser bastante extenso.

Primero explicaremos el funcionamiento de YOLOv5 con Ultralytics.

#### Uso de la API con Flask

La API desarrollada con Flask sirve como el n√∫cleo del proyecto, facilitando la comunicaci√≥n entre el modelo de detecci√≥n de objetos YOLOv5 y el chatbot basado en OpenAI. Esta API maneja tanto el procesamiento de im√°genes en tiempo real mediante WebSockets como la interacci√≥n con el chatbot mediante solicitudes REST.

#### Configuraci√≥n del Entorno

Antes de ejecutar la API, es necesario asegurarse de que se tienen instaladas todas las dependencias necesarias. Se pueden instalar mediante:

```bash
pip install -r requirements.txt
python app.py
```

(Aconsejable hacer un environment si necesitas versiones espec√≠fica)

Como la versi√≥n de Python que usamos era la 3.10, con ejecutar el comando de arriba, te instalar√° siempre lo √∫ltimo de esta versi√≥n en concreto de python.

#### Uso de WebSocket para Detecci√≥n de Objetos con YOLOv5

La API emplea flask_socketio para recibir im√°genes desde el frontend en tiempo real, procesarlas con YOLOv5 y devolver las detecciones correspondientes.

#### Flujo de Trabajo

- El frontend env√≠a frames codificados en base64 mediante WebSocket.

- La API recibe y decodifica la imagen, luego la redimensiona para mejorar la eficiencia.

- YOLOv5 procesa la imagen y genera predicciones sobre los objetos detectados.

- La API env√≠a las detecciones de vuelta al frontend a trav√©s de WebSocket.

![api_websocket](https://github.com/user-attachments/assets/0be421ff-2753-4eea-8bb0-560b6aa6c703)

Aunque la anterior imagen representa la funci√≥n y puede ser engorrosa, la siguiente captura ser√° la zona importante y vital de entender.
Esta parte es la m√°s importante ya que sin ella, no podr√≠amos representar en el frontend mediante el uso de canvas, pintar los rect√°ngulos de la detecci√≥n de objetos ya que nos da:
- Las posiciones de cada objeto
- Redonde el score del objeto a 2 decimales
- Gracias a la id, accedemos al nombre de la clase, por ejemplo, 0 - Persona
- A√±adimos esto a una lista finalmente
  
![api_socket2](https://github.com/user-attachments/assets/fe737556-a178-4f62-af07-5f0f63d33886)

#### Uso de API REST para el Chatbot Personalizado

Para permitir que los usuarios interact√∫en con el chatbot, la API implementa un endpoint /chat que recibe preguntas del usuario y responde bas√°ndose en el contenido del README.md del proyecto.

#### Flujo de Trabajo

- El usuario env√≠a una solicitud POST a /chat con el mensaje en formato JSON.

- La API obtiene el contenido del README.md desde GitHub.

- Se construye un mensaje para OpenAI combinando la pregunta del usuario y la informaci√≥n del README.md.

- La API env√≠a la solicitud a OpenAI y devuelve la respuesta generada.

La parte del frontend ser√° expuesta en la secci√≥n **8. Desarrollo de la Aplicaci√≥n Web**

![api_rest](https://github.com/user-attachments/assets/1045acd4-a22b-44f2-ae54-376e16ca642e)

Vemos aqu√≠ mas directamente la parte importante, que usar√° el rol de system, con lo cual nos permite generar un prompt anterior al promt del usuario, donde gracias a esta funci√≥n, transformamos el readme...
![readme](https://github.com/user-attachments/assets/fc3a12d0-7bfc-4919-8424-545b98158e73)

Para conseguir as√≠ finalmente que "sesgemos" al modelo para que responda preguntas con base en nuestro Readme.
![api_chat2](https://github.com/user-attachments/assets/b0b03eec-27d0-43eb-b092-d6e35d641c51)

Las dem√°s lineas de c√≥digo son necesarias para permisos y utilidad como:

**CORS**
![cors1](https://github.com/user-attachments/assets/8f0fc1bd-7060-4089-80d7-5c7b572813e0)
![cors2](https://github.com/user-attachments/assets/cd79b6b5-5ae4-402f-9195-57947fed27bf)

**Optimizaci√≥n YOLO**
![yolo1](https://github.com/user-attachments/assets/15184317-f9f6-4be5-ab08-e465cf3b873e)

## 7. Se tiene que incluir alguna de las t√©cnicas estudiadas en el tema de Procesamiento de Lenguaje Natural: expresiones regulares, tokenizaci√≥n, generaci√≥n de texto, an√°lisis de sentimientos, etc.


## 8. Desarrollo de la Aplicaci√≥n Web

Nuestra aplicaci√≥n web ha sido desarrollada utilizando **React** e **Ionic** con **TypeScript**, proporcionando una experiencia moderna y responsiva. A continuaci√≥n, describimos los principales componentes de la web junto con capturas del c√≥digo y la interfaz.

### 8.1 Estructura del Proyecto

El proyecto se organiza en distintos componentes de React y p√°ginas espec√≠ficas para cada funcionalidad. Nuestra estructura principal incluye:
- **Home.tsx** (P√°gina de inicio)
- **Model.tsx** (M√≥dulo de detecci√≥n de objetos)
- **AboutUs.tsx** (Informaci√≥n del equipo)
- **Chatbot.tsx** (Asistente virtual basado en IA)

Con esta organizaci√≥n permitimos una estructura modular y escalable. üöÄ

### 8.2 Inicio (Home.tsx)

Nuestra p√°gina principal (**Home.tsx**) presenta el proyecto y enlaza a su repositorio en GitHub. Hemos utilizado iconos para mejorar la accesibilidad visual.

#### ¬øQu√© hace este archivo?
- Muestra el dise√±o principal: Incluimos el encabezado, el contenido y cualquier elemento visual que queramos resaltar.
- Carga datos si es necesario: Dependiendo de lo que queremos mostrar, aqu√≠ podemos traer informaci√≥n desde una API o una base de datos.
- Facilita la navegaci√≥n: Agregamos enlaces o botones para que los usuarios puedan moverse dentro de nuestra aplicaci√≥n.
  
---

#### 8.2.1 Importaci√≥n de librer√≠as y estilos
El archivo `Home.tsx` es un componente de React que utiliza Ionic y otros elementos para la estructura y dise√±o de la pantalla principal de la aplicaci√≥n.

üìå C√≥digo de importaci√≥n:
![image](https://github.com/user-attachments/assets/b3ce7a56-9c89-4614-93ee-706c37b11121)

---

#### 8.2.2 Contenido de la p√°gina
En la secci√≥n principal de la pantalla, mostramos el t√≠tulo del proyecto junto con una breve descripci√≥n para que los usuarios comprendan su prop√≥sito de inmediato. Adem√°s, proporcionamos enlaces directos a los repositorios de GitHub, tanto para la web como para la API, con iconos interactivos que facilitan el acceso.

üìå C√≥digo del contenido:
![image](https://github.com/user-attachments/assets/1d891c5d-278b-42b3-8b11-5adc13391e66)

---

#### 8.2.3 Estilos Aplicados
En `Home.css`, definimos estilos para mejorar la apariencia del componente. 

üìå Ejemplo de dise√±o:

![image](https://github.com/user-attachments/assets/2b9051a9-4ea8-4f39-bdbf-de611e44f181)

Con estos estilos nos aseguramos que la p√°gina tenga un dise√±o centrado y est√©tico.


‚ú® **Vista de la p√°gina de inicio:**  

![image](https://github.com/user-attachments/assets/a850f36f-605a-406a-a75b-50b4e671ce34)


Esta p√°gina brinda una bienvenida clara y acceso directo a la informaci√≥n clave del proyecto. üöÄ

## 8.3 Modelo de Detecci√≥n de Objetos (Model.tsx)

En esta p√°gina implementamos la detecci√≥n de objetos en tiempo real utilizando la c√°mara del dispositivo. Para ello, hacemos uso de WebSockets para enviar frames al backend y recibir las detecciones procesadas.

#### ¬øQu√© hace este archivo?
- Captura video en tiempo real desde la c√°mara del dispositivo. El c√≥digo a continuaci√≥n solicita permisos para acceder a la c√°mara del dispositivo y captura el video en tiempo real:
  
  ![image](https://github.com/user-attachments/assets/9d704801-afd2-4f15-8cb7-8563a47fdeb5)

- Env√≠a frames al backend. Usa WebSockets para enviar im√°genes a la API, donde se realiza la detecci√≥n de objetos.

  ![image](https://github.com/user-attachments/assets/3045fff8-ff73-4c49-b901-24192edad290)

  
- Recibe y dibuja detecciones. Recibe los resultados del backend y los dibuja sobre el video en un canvas.

  ![image](https://github.com/user-attachments/assets/aa6c6931-02fe-444d-83f4-0db89417b673)

---

#### 8.3.1 Importaci√≥n de librer√≠as y estilos
El archivo Model.tsx importa las siguientes librer√≠as:

- react, useEffect, useRef: Para gestionar el ciclo de vida del componente y referencias.
- socket.io-client: Para la comunicaci√≥n en tiempo real con el backend.
- @ionic/react: Para la estructura de la p√°gina en Ionic.
- @capacitor/core y @capacitor/status-bar: Para ajustar la interfaz en dispositivos m√≥viles.

üìå C√≥digo de importaci√≥n:
![image](https://github.com/user-attachments/assets/44c13030-c11c-450b-8eff-bf19317438da)

---

#### 8.3.2 Contenido de la p√°gina
Esta secci√≥n estructura la interfaz del m√≥dulo:

- Video en vivo: Capturamos la imagen de la c√°mara.
- Canvas de detecciones: Dibujamos los resultados del modelo de IA sobre el video.

üìå C√≥digo del contenido:
![image](https://github.com/user-attachments/assets/a9428b16-d8ba-474a-9211-cdd2a1f4d686)

---

#### 8.3.3 Comunicaci√≥n con el Backend

Conexi√≥n al Backend (A nivel local)
![image](https://github.com/user-attachments/assets/9f55390b-f505-409d-a544-9972425c4e85)

Aqu√≠ se establece la conexi√≥n con el backend en el puerto 5000.

Cuando el backend detecta objetos en el frame enviado, devuelve las coordenadas y la confianza del modelo. Este c√≥digo se encarga de dibujar los resultados sobre el video:

![image](https://github.com/user-attachments/assets/61bd5e5d-8bb5-4451-8c40-a219badb81d9)

Desconecta el socket cuando el usuario sale de la p√°gina:

![image](https://github.com/user-attachments/assets/c6493fce-0297-4b97-a311-39f34df48f0a)

---

#### 8.3.4 Estilos Aplicados
En Model.css, definimos estilos para:

Centrar el video en pantalla.
Ajustar el tama√±o del video y el canvas.
Aplicar un fondo con degradado.

üìå Ejemplo de dise√±o:
![image](https://github.com/user-attachments/assets/c44fcc65-8273-48ec-b1da-ffd645ccf3e7)


‚ú® **Vista del modelo de detecci√≥n de objetos:**

[Imagen del modelo funcionando]

Con esta implementaci√≥n logramos un procesamiento √°gil y preciso, permitiendo a los usuarios identificar objetos en tiempo real de manera intuitiva y eficaz. üéØ

## 8.4 Informaci√≥n del Equipo (AboutUs.tsx)

En esta p√°gina mostramos a los integrantes del equipo de desarrollo. En la p√°gina se puede visualizar una lista de miembros, su rol, su formaci√≥n y enlaces a sus perfiles de GitHub y LinkedIn.

‚ú® **Vista de la p√°gina de Informaci√≥n del Equipo:**

![image](https://github.com/user-attachments/assets/e2236a86-5f5f-44dc-82c4-b8aa7872afaa)


## 8.5 Chatbot (Chatbot.tsx)

En esta p√°gina implementamos un chatbot interactivo que permite a los usuarios realizar preguntas. Utilizamos un backend en Node.js para procesar las consultas y devolver respuestas din√°micas.

### ¬øQu√© hace este archivo?
- **Muestra un chatbot en la aplicaci√≥n.**
- **Permite la interacci√≥n con el usuario.** El usuario puede escribir preguntas y recibir respuestas en tiempo real.
- **Env√≠a consultas a un backend en Node.js.** Se conecta a un servidor en `http://localhost:5000/chat` para procesar los mensajes.
- **Formatea las respuestas.** Convierte ciertos elementos de texto como negritas y listas en formato HTML para mejorar la legibilidad.

---

### 8.5.1 Importaci√≥n de librer√≠as y estilos
El archivo `Chatbot.tsx` importa las siguientes librer√≠as:

- **react, useState**: Para gestionar el estado del chatbot y los mensajes.
- **axios**: Para enviar solicitudes HTTP al backend.
- **@ionic/react**: Para la estructura de la p√°gina.
- **Footer**: Componente reutilizable para el pie de p√°gina.
- **Chatbot.css**: Archivo de estilos para la apariencia del chatbot.

üìå **C√≥digo de importaci√≥n:**
![image](https://github.com/user-attachments/assets/8822090b-325f-4af6-aa1f-72307de3ce1f)


### 8.5.2 Estado y manejo de mensajes
Almacenamos los mensajes en un array gestionado con `useState`. Inicialmente, contiene un mensaje de bienvenida del bot:

üìå **C√≥digo de inicializaci√≥n:**
![image](https://github.com/user-attachments/assets/bf0786c2-d521-4084-a8a0-e469a4a0aa52)
![image](https://github.com/user-attachments/assets/59699bd8-f7bf-437c-bffb-d92c8e92b76d)


El usuario puede escribir un mensaje y enviarlo con `sendMessage()`, que realiza las siguientes acciones:
1. Agrega el mensaje del usuario al estado.
2. Env√≠a la consulta al backend mediante una petici√≥n `POST`.
3. Recibe la respuesta del servidor y la formatea.
4. Agrega la respuesta del chatbot a la conversaci√≥n.
5. Limpia el input despu√©s de enviar el mensaje.

üìå **C√≥digo de env√≠o de mensajes:**
![image](https://github.com/user-attachments/assets/f6eabbe7-1417-42dd-88b0-25fa0b26bf11)


---

### 8.5.3 Renderizado del Chatbot

El chatbot se compone de:
- Un **contenedor de mensajes**, donde se muestran las interacciones previas.
- Un **input de texto** para que el usuario escriba su mensaje.
- Un **bot√≥n de env√≠o** para enviar mensajes manualmente.
- La posibilidad de presionar **Enter** para enviar el mensaje.

üìå **C√≥digo del renderizado:**
![image](https://github.com/user-attachments/assets/ef0402ba-5a17-42e8-8ef4-591904aab9c8)


---

### 8.5.4 Formateo de respuestas

Para mejorar la presentaci√≥n de las respuestas, convertimos ciertos elementos a formato HTML:
- **Negritas**: `**texto**` ‚Üí `<strong>texto</strong>`
- **Saltos de l√≠nea**: `\n` ‚Üí `<br>`
- **Listas numeradas**: `1. Texto` ‚Üí `‚Ä¢ Texto`

üìå **C√≥digo de formateo:**
![image](https://github.com/user-attachments/assets/ac19de25-1edd-4c50-b5e9-ac02fcf076a0)



---

‚ú® **Vista del chatbot funcionando:**

[Imagen del chatbot]

Con esta implementaci√≥n ofrecemos una experiencia fluida y responsiva, permitiendo a los usuarios interactuar con el asistente virtual de manera sencilla y eficiente. üöÄ

