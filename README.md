<## 1. JustificaciÃ³n y descripciÃ³n del proyecto.

![image](https://github.com/user-attachments/assets/d390cd52-737d-452c-8a5a-40f28d50fd2c)## 1. JustificaciÃ³n y descripciÃ³n del proyecto.
### **Desarrolladores**

- Alejandro FernÃ¡ndez Barrionuevo
- AdriÃ¡n Perogil FernÃ¡ndez
- Carlos

### **TÃ­tulo**

InnerVisionAI

### **DescripciÃ³n**

Un proyecto basado en detecciÃ³n de obstÃ¡culos donde, gracias al uso de YOLO, podemos detectar con una cÃ¡mara todo tipo de objetos en la vida real.

Su uso escalable y la intenciÃ³n con la que se hizo este proyecto fue para ayudar a personas con discapacidades visuales que mediante audio, guiara a las personas
y pudiera recibir un feedback en todo momento, asÃ­ pudiendo caminar con mayor comodidad y seguridad. 

Como el tiempo que tuvimos era limitado y era muy ambicioso, nos vimos en la obligaciÃ³n de pensar "niveles" para empezar con algo bÃ¡sico hasta llegar al target.

### **CÃ³digo fuente**

[WEB](https://github.com/imchopi/InnerVisionAI/tree/feature_alex)

[API](https://github.com/imchopi/API_InnerVisionAI)

### **PresentaciÃ³n en formato PDF**

PrÃ³ximamente...

### **Enlace a la aplicaciÃ³n web**

[PÃ¡gina Web](https://innervisionai.netlify.app/home)

### **Recursos utilizados**

- Jira
- YOLOv5
- Roboflow
- Google Colab
- Flask
- React e Ionic
- TypeScript
- Socket.IO
- OpenAI API
- Node.js
- Axios
- GitHub
- Netlify
- Python
- HTML/CSS
- Markdown
- Base64
- CSV
- Git
- DeepSeek
- ChatGPT
- Diversos Foros
- Claude  
- BeuatifulSoup
- Selenium
- AWS Glue 
- DocumentaciÃ³n de AWS
- Youtube 
- Regex 


### **VÃ­deo**

PrÃ³ximamente...

### **Porcentaje que le corresponde a cada miembro del trabajo realizado de dicho proyecto.**

- Alejandro FernÃ¡ndez Barrionuevo ()
- AdriÃ¡n Perogil FernÃ¡ndez ()
- Carlos ()


## 2. ObtenciÃ³n de datos. Se debe especificar la fuente de los datos. Se indicarÃ¡ por quÃ© medios se han obtenido (encuestas, sensores, scrapping, etc.). Los datos se deben cargar en una estructura que permita su posterior manipulaciÃ³n y uso.

Para conseguir los datos que necesitÃ¡bamos, decidimos extraer imÃ¡genes de internet ğŸ–¼ï¸. Como nuestro modelo va a funcionar en tiempo real â³, querÃ­amos que reconociera objetos comunes en la empresa, como sillas, armarios y mesas ğŸª‘ğŸ“¦.

Por eso elegimos IKEA ğŸ  como fuente de informaciÃ³n, ya que es una de las mejores referencias y sabemos que tiene justo lo que estÃ¡bamos buscando âœ….

Lo primero que hicimos fue instalar las librerÃ­as necesarias ğŸ› ï¸. Al principio, como la web parecÃ­a sencilla ğŸŒ, pensamos que con BeautifulSoup ğŸ¥£ serÃ­a suficiente, pero no fue asÃ­ âŒ.

Si querÃ­amos cargar todas las imÃ¡genes ğŸ–¼ï¸, nos dimos cuenta de que habÃ­a un botÃ³n de "Mostrar mÃ¡s", que era el encargado de cargar las imÃ¡genes.

Para solucionar este problema, utilizamos Selenium ğŸš—ğŸ’¨, que nos permite interactuar con la web como si fuÃ©ramos un usuario real.

A continuaciÃ³n, explicarÃ© las librerÃ­as que usaremos ğŸ“š para llevar a cabo la extracciÃ³n de datos ğŸ”.

### ğŸ“Œ LibrerÃ­as utilizadas para la extracciÃ³n de datos

<img src="Imagenes/IKEA/Imagen-1.png" width="600" height="300">

Para poder extraer informaciÃ³n de la web, utilizamos varias librerÃ­as ğŸ“š que nos ayudarÃ¡n en diferentes tareas:

os ğŸ“‚ â†’ Nos permite interactuar con los archivos y carpetas de nuestro sistema.

time â³ â†’ Se usa para pausar el cÃ³digo y esperar antes de realizar ciertas acciones.

requests ğŸŒ â†’ Nos ayuda a hacer peticiones a sitios web y obtener su contenido.

re ğŸ” â†’ Se usa para trabajar con patrones de texto, como encontrar enlaces o filtrar datos.
BeautifulSoup (de bs4) ğŸ¥£ â†’ Nos permite extraer informaciÃ³n de una pÃ¡gina web de forma mÃ¡s sencilla.

ğŸš€ AutomatizaciÃ³n con Selenium

webdriver ğŸš— â†’ Nos permite controlar un navegador web (como Chrome).

Service ğŸ› ï¸ â†’ Maneja la configuraciÃ³n del navegador para Selenium.

Options âš™ï¸ â†’ Nos ayuda a establecer preferencias para el navegador (como abrirlo en modo 
invisible).

By ğŸ” â†’ Se usa para encontrar elementos dentro de la pÃ¡gina web.

WebDriverWait â³ â†’ Permite que el cÃ³digo espere hasta que un elemento de la web aparezca.

expected_conditions (EC) âœ… â†’ Nos ayuda a esperar hasta que ciertas condiciones se cumplan, como que un botÃ³n sea visible antes de hacer clic.

## ğŸ” Estructura del CÃ³digo  

Lo siguiente que mostrarÃ© es un poco cÃ³mo he **organizado** este cÃ³digo ğŸ“œ.  

Voy a explicar **cada parte** para que sea fÃ¡cil de entender y seguir ğŸ“Œ.  

---

<img src="Imagenes/IKEA/Imagen-2.png" width="700" height="400">

# ğŸ–¥ï¸ Clase IKEA Scraper

Esta clase se encarga de **extraer informaciÃ³n** de la web de **IKEA** ğŸ , especÃ­ficamente imÃ¡genes de **armarios, mesas y sillas**.  

## ğŸ“Œ 1. InicializaciÃ³n (`__init__` method)  
Cuando creamos un objeto de esta clase, se ejecuta este cÃ³digo automÃ¡ticamente.  

### ğŸ”— `self.category_urls`  
- Es un diccionario que contiene las **categorÃ­as de muebles** y los enlaces de IKEA donde estÃ¡n los productos ğŸ“¦.  
- Por ejemplo, para obtener **armarios**, el cÃ³digo buscarÃ¡ en:  
  - `"https://www.ikea.com/es/es/cat/armarios-19053/"`  

### ğŸ·ï¸ `self.headers`  
- Sirve para **simular** que el navegador es un usuario real y evitar bloqueos de la web.  
- AquÃ­ se usa un **"User-Agent"** (que le dice a la web que estamos usando un navegador como Chrome o Firefox).  

---

## ğŸš€ 2. ConfiguraciÃ³n del navegador con Selenium  
Como la web tiene **botones interactivos**, usamos **Selenium** para controlarla automÃ¡ticamente.  

### âš™ï¸ `chrome_options = Options()`  
- Nos permite **configurar** cÃ³mo se abrirÃ¡ el navegador.  
- `chrome_options.add_argument("--start-maximized")` ğŸ–¥ï¸  
  - Abre el navegador en **pantalla completa** para evitar problemas con elementos ocultos.  

### ğŸš— `self.driver = webdriver.Chrome(...)`  
- AquÃ­ estamos **iniciando Chrome** para que Selenium pueda interactuar con la web **como si fuera un usuario real**.  

---

<img src="Imagenes/IKEA/Imagen-3.png" width="600" height="300">

## ğŸ“ FunciÃ³n `create_directories`

Esta funciÃ³n se encarga de **crear carpetas** en el sistema para almacenar las imÃ¡genes de cada categorÃ­a ğŸ—‚ï¸.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Obtiene las categorÃ­as** ğŸ·ï¸  
   - Usa `self.category_urls.keys()` para obtener la lista de categorÃ­as disponibles (ejemplo: "sillas", "mesas", "armarios").  

2. **Crea una carpeta para cada categorÃ­a** ğŸ“‚  
   - Recorre la lista de categorÃ­as y construye la ruta donde se guardarÃ¡n los datos.  
   - Usa `os.path.join(base_path, category)` para combinar la ruta base con el nombre de la categorÃ­a.  

3. **Verifica si la carpeta existe** âœ…  
   - Si la carpeta **no existe**, se crea con `os.makedirs(path)`.  

4. **Devuelve la lista de categorÃ­as** ğŸ”„  
   - Retorna la lista de categorÃ­as que se crearon.  

--- 

<img src="Imagenes/IKEA/Imagen-4.png" width="600" height="300"> 

## ğŸ–¼ï¸ FunciÃ³n `download_image`

Esta funciÃ³n **descarga una imagen desde una URL y la guarda en el sistema** ğŸ“¥ğŸ“‚.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Hace una solicitud a la URL** ğŸŒ  
   - Utiliza `requests.get(url, headers=self.headers)` para obtener la imagen desde el enlace.  
   - Usa **`self.headers`** para simular una peticiÃ³n desde un navegador y evitar bloqueos.  

2. **Verifica que la imagen se haya descargado correctamente** âœ…  
   - Si el cÃ³digo de respuesta (`response.status_code`) es `200`, significa que la imagen se descargÃ³ sin problemas.  

3. **Guarda la imagen en el archivo especificado** ğŸ’¾  
   - Abre el archivo en modo escritura binaria (`'wb'`).  
   - Escribe el contenido de la imagen en el archivo.  
   - Imprime un mensaje confirmando que la imagen se guardÃ³ correctamente.  

4. **Manejo de errores** âš ï¸  
   - Si ocurre un error en la descarga, se captura con `except Exception as e`.  
   - Se imprime un mensaje indicando el problema y la funciÃ³n devuelve `False`.  

---

<img src="Imagenes/IKEA/Imagen-5.png" width="600" height="300"> 

## ğŸ”„ FunciÃ³n `load_all_products`

Esta funciÃ³n **carga todos los productos de la pÃ¡gina web** haciendo clic en el botÃ³n `"Mostrar mÃ¡s"` hasta que ya no haya mÃ¡s productos disponibles ğŸ›ï¸.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Abre la pÃ¡gina web** ğŸŒ  
   - Utiliza `self.driver.get(url)` para acceder a la URL proporcionada.  

2. **Espera a que la pÃ¡gina cargue** â³  
   - Crea una espera con `WebDriverWait` para asegurarse de que los elementos estÃ©n listos antes de interactuar con ellos.  

3. **Bucle para cargar mÃ¡s productos** ğŸ”„  
   - Se usa un `while True` para hacer clic en `"Mostrar mÃ¡s"` varias veces.  
   - **Busca el botÃ³n** con `wait.until(...)` y verifica que sea **clickeable**.  
   - **Ejecuta un clic** en el botÃ³n con `execute_script("arguments[0].click();", load_more_button)`.  
   - Muestra el mensaje `"Cargando mÃ¡s productos..."` en la terminal.  
   - Espera `2 segundos` (`time.sleep(2)`) antes de intentar hacer clic nuevamente.  

4. **Manejo de errores** âš ï¸  
   - Si el botÃ³n `"Mostrar mÃ¡s"` ya no estÃ¡ disponible, significa que **no hay mÃ¡s productos**.  
   - En ese caso, se muestra el mensaje `"No hay mÃ¡s productos para cargar."` y el bucle se detiene con `break`.

---

<img src="Imagenes/IKEA/Imagen-6.png" width="800" height="500"> 

## ğŸ” FunciÃ³n `scrape_category`

Esta funciÃ³n **extrae imÃ¡genes de productos** de una **categorÃ­a especÃ­fica** en IKEA ğŸ  y las guarda en una carpeta ğŸ“‚.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Carga la pÃ¡gina de la categorÃ­a** ğŸŒ  
   - Obtiene la URL de la categorÃ­a desde `self.category_urls[category]`.  
   - Llama a `self.load_all_products(url)`, que se encarga de hacer clic en `"Mostrar mÃ¡s"` hasta que todos los productos estÃ©n cargados.  

2. **Extrae los productos con `BeautifulSoup`** ğŸ¥£  
   - Obtiene el cÃ³digo HTML de la pÃ¡gina con `self.driver.page_source`.  
   - Busca todos los productos en la web usando `soup.find_all('div', class_='plp-fragment-wrapper')`.  

3. **Recorre cada producto y extrae su informaciÃ³n** ğŸ”„  
   - Para cada producto, intenta encontrar:  
     - La **imagen** (`<img>`) y su URL.  
     - El **nombre del producto** dentro de un `<span>`.  

4. **Limpia el nombre del producto** ğŸ·ï¸  
   - Si el nombre contiene caracteres especiales, los reemplaza con `_` usando `re.sub()`.  
   - Si no se encuentra un nombre, usa un nombre genÃ©rico basado en la categorÃ­a y el Ã­ndice (`category_idx`).  

5. **Descarga la imagen** ğŸ“¥  
   - Guarda la imagen en la ruta `save_path`, nombrÃ¡ndola con el nombre limpio.  
   - Llama a `self.download_image(img_url, image_path)`, que descarga y guarda la imagen.  
   - Muestra un mensaje en la terminal confirmando la descarga.  

6. **Manejo de errores** âš ï¸  
   - Si hay un problema al procesar un producto, muestra un mensaje de error y pasa al siguiente.  

---

<img src="Imagenes/IKEA/Imagen-7.png" width="800" height="500"> 

## ğŸš€ FunciÃ³n `run`

Esta funciÃ³n **ejecuta el scraping completo** en todas las categorÃ­as definidas ğŸ ğŸ”„.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Muestra un mensaje de inicio** ğŸ“¢  
   - Se imprime `"Iniciando proceso de scraping..."` para indicar que el proceso ha comenzado.  

2. **Crea los directorios para cada categorÃ­a** ğŸ“‚  
   - Llama a `self.create_directories(base_path)`, que se encarga de crear carpetas donde se guardarÃ¡n las imÃ¡genes.  
   - Muestra en la terminal las categorÃ­as para las cuales se han creado carpetas.  

3. **Realiza el scraping de cada categorÃ­a** ğŸ”„  
   - **Recorre todas las categorÃ­as disponibles** usando un `for`.  
   - **Imprime un mensaje indicando que estÃ¡ iniciando el scraping** de esa categorÃ­a.  
   - Genera la ruta donde se guardarÃ¡n las imÃ¡genes (`category_path`).  
   - Llama a `self.scrape_category(category, category_path)`, que extrae las imÃ¡genes de la web.  
   - Muestra un mensaje indicando que el scraping de esa categorÃ­a ha finalizado.  
   - **Espera 3 segundos (`time.sleep(3)`)** antes de pasar a la siguiente categorÃ­a.  

4. **Cierra el navegador** ğŸ”š  
   - Llama a `self.driver.quit()`, lo que finaliza el uso de Selenium y cierra el navegador.  

--- 

<img src="Imagenes/IKEA/Imagen-8.png" width="600" height="300"> 

## ğŸ EjecuciÃ³n del scraper en local

Este bloque de cÃ³digo **inicia el proceso de scraping** cuando ejecutamos el script en nuestro ordenador ğŸ–¥ï¸.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Verifica si el script se estÃ¡ ejecutando directamente** ğŸ—ï¸  
   - La condiciÃ³n `if __name__ == "__main__":` se asegura de que el cÃ³digo **solo se ejecute** cuando ejecutamos el archivo directamente y no si se importa como mÃ³dulo en otro script.  

2. **Crea una instancia del scraper** ğŸ   
   - Se inicializa un objeto `IKEAScraper`, indicando la ruta del **ChromeDriver** (`chromedriver.exe`).  
   - `ChromeDriver` es necesario para que **Selenium** pueda controlar el navegador.  

3. **Ejecuta el proceso completo de scraping** ğŸš€  
   - Se llama a `scraper.run()`, que se encargarÃ¡ de:
     - Abrir el navegador.
     - Extraer los productos de todas las categorÃ­as.
     - Descargar las imÃ¡genes.
     - Guardarlas en carpetas organizadas.

---

## ğŸ–¥ï¸ Ampliando el scraping: objetos mÃ¡s pequeÃ±os  

DespuÃ©s de extraer informaciÃ³n sobre **muebles**, decidimos tambiÃ©n obtener datos de **objetos mÃ¡s pequeÃ±os** que se pueden encontrar dentro de la empresa, como **teclados, portÃ¡tiles y ratones** âŒ¨ï¸ğŸ’»ğŸ–±ï¸.  

### ğŸ” Cambio de fuente: PCComponentes  
Para estos productos, optamos por **extraer la informaciÃ³n de PCComponentes** ğŸ›’.  

Sin embargo, pronto nos dimos cuenta de una **diferencia clave** con la web de IKEA:  
ğŸ”¹ **No tenÃ­a un botÃ³n de "Cargar mÃ¡s"** como IKEA.  
ğŸ”¹ En su lugar, habÃ­a un **botÃ³n para pasar a la siguiente pÃ¡gina** ğŸ“„â¡ï¸.  

### ğŸš§ Problema encontrado: Bloqueo de bots  
Cuando intentamos **pasar a la siguiente pÃ¡gina**, la web nos detectaba como **un bot** ğŸš«ğŸ¤–, impidiendo que siguiÃ©ramos navegando.  

### ğŸ’¡ SoluciÃ³n ingeniosa  
Para **evitar el bloqueo**, encontramos una soluciÃ³n **sencilla pero efectiva**:  

ğŸ”„ En lugar de hacer clic en **"Siguiente pÃ¡gina"**, usamos un **bucle** que:  
1. **Scrapea** la informaciÃ³n de la pÃ¡gina actual.  
2. **Cierra el navegador** completamente.  
3. **Vuelve a abrirlo** en la siguiente pÃ¡gina con la nueva URL.  

ğŸ“Œ **Resultado:** La web no detectaba que Ã©ramos un bot, permitiÃ©ndonos extraer la informaciÃ³n sin problemas ğŸ¯.  

---

## ğŸ–¥ï¸ CÃ³digo para extraer datos de PCComponentes  

En esta situaciÃ³n, utilizaremos **tres cÃ³digos similares** ğŸ”„, pero con algunos **detalles especÃ­ficos** cambiados para que cada uno **interactÃºe con su categorÃ­a correspondiente**.  

ğŸ“Œ **Las tres categorÃ­as a scrapear son:**  
- **Teclados** âŒ¨ï¸  
- **PortÃ¡tiles** ğŸ’»  
- **Ratones** ğŸ–±ï¸  

Dado que los cÃ³digos son casi **idÃ©nticos**, solo mostrarÃ© el cÃ³digo correspondiente a **los ratones** ğŸ–±ï¸, ya que la lÃ³gica es la misma para los otros dos casos, con pequeÃ±os ajustes.  

---

ğŸ“Œ **A continuaciÃ³n, el cÃ³digo para extraer informaciÃ³n de los ratones en PCComponentes** ğŸš€.

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-1.png" width="600" height="300"> 

## ğŸ“š LibrerÃ­as utilizadas para el scraping de PCComponentes  

Para poder extraer los datos de **PCComponentes**, utilizamos varias **librerÃ­as** ğŸ“¦ que nos ayudarÃ¡n en diferentes tareas:  

### ğŸ”¹ **LibrerÃ­as bÃ¡sicas**
- **`requests`** ğŸŒ â†’ Se usa para hacer peticiones a la web y obtener su contenido.  
- **`os`** ğŸ“‚ â†’ Permite interactuar con los archivos y carpetas del sistema.  
- **`time`** â³ â†’ Se usa para hacer pausas en el cÃ³digo y evitar bloqueos por sobrecarga de peticiones.  

### ğŸ¥£ **BeautifulSoup: AnÃ¡lisis del HTML**
- **`BeautifulSoup (bs4)`** ğŸ—ï¸ â†’ Se encarga de **extraer informaciÃ³n del cÃ³digo HTML** de la web.  

### ğŸš€ **Selenium: AutomatizaciÃ³n del navegador**  
Dado que la web de **PCComponentes** requiere **interacciÃ³n con la paginaciÃ³n**, usamos **Selenium** para controlarla:  

- **`webdriver`** ğŸš— â†’ Controla el navegador (Chrome en este caso).  
- **`Service`** ğŸ› ï¸ â†’ Configura la ejecuciÃ³n del navegador de forma automÃ¡tica.  
- **`Options`** âš™ï¸ â†’ Permite configurar cÃ³mo se abre el navegador (ejemplo: en modo sin interfaz).  
- **`By`** ğŸ” â†’ Se usa para buscar elementos dentro de la web (ejemplo: botones o imÃ¡genes).  
- **`WebDriverWait`** â³ â†’ Permite que el cÃ³digo **espere** hasta que un elemento de la web se cargue correctamente.  
- **`expected_conditions (EC)`** âœ… â†’ Se usa para definir condiciones antes de interactuar con elementos de la web (como esperar a que un botÃ³n sea clickeable).  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-2.png" width="600" height="300">  

## ğŸ–±ï¸ Clase `PCscrapper`

Esta clase se encarga de **extraer informaciÃ³n de los ratones en PCComponentes** ğŸ›’.  

### ğŸ› ï¸ **InicializaciÃ³n de la clase (`__init__` method)**  

Cuando creamos un objeto de esta clase, se ejecuta el cÃ³digo de inicializaciÃ³n que:  

### ğŸ”— **Define las URLs de las pÃ¡ginas a scrapear**  
- **`self.category_urls`** almacena un **diccionario de URLs**, donde cada clave es el nombre de la pÃ¡gina y el valor es la URL correspondiente.  
- Se usa un **bucle con `range(1, 29)`**, lo que indica que se van a recorrer **28 pÃ¡ginas** (de la 1 a la 28).  
- La URL cambia dinÃ¡micamente con `?page={page}`, lo que permite navegar por las diferentes pÃ¡ginas sin hacer clic en "Siguiente".  

### ğŸ·ï¸ **Define las cabeceras (`headers`)**  
- **`self.headers`** almacena un **"User-Agent"**, que hace que la peticiÃ³n parezca de un navegador real.  
- Esto ayuda a **evitar bloqueos** por parte de la web al detectar actividad sospechosa de bots ğŸ¤–ğŸš«.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-3.png" width="600" height="300"> 


## ğŸ“‚ FunciÃ³n `create_directories`

Esta funciÃ³n se encarga de **crear carpetas** en el sistema para almacenar las imÃ¡genes de cada categorÃ­a ğŸ—‚ï¸.

### ğŸ› ï¸ Â¿CÃ³mo funciona?

1. **Obtiene las categorÃ­as** ğŸ·ï¸  
   - Usa `self.category_urls.keys()` para obtener la lista de categorÃ­as disponibles (ejemplo: `"ratones1"`, `"ratones2"`, `"ratones3"`, etc.).  

2. **Crea una carpeta para cada categorÃ­a** ğŸ“‚  
   - Recorre la lista de categorÃ­as y **construye la ruta** donde se guardarÃ¡n los datos.  
   - Usa `os.path.join(base_path, category)` para combinar la ruta base con el nombre de la categorÃ­a.  

3. **Verifica si la carpeta existe** âœ…  
   - Si la carpeta **no existe**, se crea con `os.makedirs(path)`.  

4. **Devuelve la lista de categorÃ­as** ğŸ”„  
   - Retorna la lista de categorÃ­as que se crearon.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-4.png" width="800" height="300"> 

## ğŸ–¼ï¸ FunciÃ³n `download_image`

Esta funciÃ³n **descarga una imagen desde una URL y la guarda en el sistema** ğŸ“¥ğŸ“‚.

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**

1. **Hace una solicitud a la URL** ğŸŒ  
   - Usa `requests.get(url, headers=self.headers)` para obtener la imagen desde el enlace.  
   - Incluye **cabeceras HTTP (`headers`)** para **simular una peticiÃ³n real de un navegador** y evitar bloqueos.  

2. **Verifica que la imagen se haya descargado correctamente** âœ…  
   - Si el cÃ³digo de respuesta (`response.status_code`) es **200**, significa que la imagen se descargÃ³ sin problemas.  

3. **Crea el directorio si no existe** ğŸ“‚  
   - Usa `os.makedirs(os.path.dirname(path), exist_ok=True)` para asegurarse de que la carpeta donde se guardarÃ¡ la imagen **exista**.  
   - `exist_ok=True` evita errores si la carpeta ya estÃ¡ creada.  

4. **Guarda la imagen en el archivo especificado** ğŸ’¾  
   - Abre el archivo en modo escritura binaria (`'wb'`).  
   - Escribe el contenido de la imagen en el archivo.  
   - Imprime un mensaje confirmando que la imagen se guardÃ³ correctamente.  

5. **Manejo de errores** âš ï¸  
   - Si ocurre un error en la descarga, se captura con `except Exception as e`.  
   - Se imprime un mensaje indicando el problema y la funciÃ³n devuelve `False`.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-5.png" width="900" height="600"> 

## ğŸ“¸ FunciÃ³n `download_products_images`

Esta funciÃ³n **descarga imÃ¡genes de una pÃ¡gina web de manera automÃ¡tica** ğŸŒğŸ“¥.

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**

1. **Abre la pÃ¡gina web en Chrome** ğŸŒ  
   - Usa **Selenium** para abrir la URL en un navegador.  
   - Configura el navegador en **modo maximizado** para evitar problemas de visualizaciÃ³n.  

2. **Acepta las cookies si es necesario** ğŸª  
   - Busca el botÃ³n de "Aceptar cookies" y hace clic en Ã©l.  
   - Si el botÃ³n no estÃ¡ presente, **el cÃ³digo sigue sin problemas**.  

3. **Espera a que las imÃ¡genes se carguen** â³  
   - Usa `WebDriverWait` para asegurarse de que las imÃ¡genes estÃ©n visibles antes de continuar.  
   - Utiliza **BeautifulSoup** para analizar el cÃ³digo HTML de la pÃ¡gina y extraer las imÃ¡genes.  

4. **Busca y filtra imÃ¡genes relevantes** ğŸ”  
   - Extrae todas las etiquetas `<img>` que tengan atributos `src` (enlace de imagen) y `alt` (descripciÃ³n).  
   - Obtiene la URL de cada imagen.  
   - Si la URL es **relativa** (empieza con `/`), se convierte en una URL **completa** agregando el dominio.  

5. **Descarga y guarda las imÃ¡genes** ğŸ“‚  
   - Genera un **nombre de archivo Ãºnico** (`image_{i}.jpg`) y lo guarda en una carpeta segÃºn su categorÃ­a.  
   - Llama a la funciÃ³n `self.download_image()` para almacenar la imagen correctamente.  

6. **Manejo de errores y cierre del navegador** âš ï¸  
   - Si hay un error durante la ejecuciÃ³n, se muestra un mensaje con la URL afectada.  
   - Al final, **siempre se cierra el navegador** para liberar recursos.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-6.png" width="600" height="300">   

## ğŸš€ FunciÃ³n `run`

Esta funciÃ³n **ejecuta el scraper** y se encarga de **organizar y descargar las imÃ¡genes** de diferentes categorÃ­as ğŸ“¥ğŸ“‚.

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**

1. **Define la carpeta base donde se guardarÃ¡n las imÃ¡genes** ğŸ“‚  
   - `base_path = 'images'` establece el directorio principal donde se almacenarÃ¡n las imÃ¡genes descargadas.  

2. **Crea las carpetas necesarias** ğŸ—ï¸  
   - Usa `self.create_directories(base_path)` para asegurarse de que la carpeta base **exista antes de guardar las imÃ¡genes**.  
   - Si la carpeta ya existe, **evita errores y continÃºa con la ejecuciÃ³n**.  

3. **Recorre todas las categorÃ­as de productos** ğŸ·ï¸  
   - Usa un **bucle `for`** para iterar sobre `self.category_urls.items()`, donde cada categorÃ­a tiene una URL especÃ­fica.  
   - Extrae la `category` (nombre de la categorÃ­a) y `url` (direcciÃ³n web donde se encuentran las imÃ¡genes).  

4. **Llama a la funciÃ³n de descarga de imÃ¡genes** ğŸ“¸  
   - `self.download_products_images(url, category)` procesa la pÃ¡gina y **descarga las imÃ¡genes correspondientes a cada categorÃ­a**.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones/imagen-7.png" width="600" height="300">  

## ğŸ–¥ï¸ Bloque `if __name__ == "__main__"`

Este bloque de cÃ³digo **ejecuta el programa en local** y **pone en marcha el scraper** ğŸğŸš€.

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**

1. **Verifica que el script se estÃ¡ ejecutando directamente** â–¶ï¸  
   - La lÃ­nea `if __name__ == '__main__':` **asegura que el cÃ³digo solo se ejecute si este archivo es ejecutado directamente**, y **no si es importado como mÃ³dulo en otro script**.  

2. **Crea una instancia del scraper** ğŸ—ï¸  
   - `scrapper = PCscrapper()` inicializa un objeto de la clase `PCscrapper`, que contiene toda la lÃ³gica del scraping.  
   - AquÃ­ se configuran las opciones y los parÃ¡metros del scraper.  

3. **Ejecuta el scraper** ğŸ”„  
   - `scrapper.run()` llama a la funciÃ³n `run()` para iniciar la **descarga y organizaciÃ³n de imÃ¡genes** desde las pÃ¡ginas web.  
   - Esto hace que **se ejecuten todos los procesos del scraper automÃ¡ticamente**.  

---

# ğŸ–¥ï¸ **Scraping de datos de ratones en PCComponentes para Power BI** ğŸ“ŠğŸ­  

Para la **visualizaciÃ³n de datos en Power BI**, pensÃ© que ya tenÃ­a las imÃ¡genes, asÃ­ queâ€¦ **Â¿quÃ© tan difÃ­cil podrÃ­a ser obtener los datos de los ratones ?** ğŸ¤”  

Bueno, resultÃ³ ser **el mayor reto al que me he enfrentado**.  

### ğŸš§ **El desafÃ­o**  
Por mÃ¡s que intentaba localizar los datos, **cambiaba el nombre de las class una y otra vez**, pero nada funcionaba. Cuando estaba **a punto de rendirme**, tomÃ© aire, suspirÃ© y decidÃ­ empezar **desde cero, paso a paso**.  

### ğŸ” **Paso a paso, desentraÃ±ando los datos**  
1ï¸âƒ£ **Extraer el nombre**: Fue lo mÃ¡s fÃ¡cil, asÃ­ que comencÃ© por ahÃ­. âœï¸  
2ï¸âƒ£ **Obtener el precio**: Perfecto, ahora tenÃ­a **2 de los 5 datos** que necesitaba. ğŸ’°  
3ï¸âƒ£ **Conseguir la URL**: Tras algunos intentos, me di cuenta de que todas las URLs seguÃ­an el mismo patrÃ³n:  
   **Dominio de la web + Nombre del producto** ğŸŒğŸ”—  
   Â¡Un descubrimiento clave! De repente, **todas las URLs estaban listas**.  
4ï¸âƒ£ **Valoraciones y cantidad de opiniones**: Ahora que entendÃ­a la estructura, estos datos vinieron **de inmediato**. â­ğŸ’¬  

### ğŸ”„ **El problema de la paginaciÃ³n**  
Cuando intentÃ© pasar a la **siguiente pÃ¡gina**, **el navegador no respondÃ­a correctamente**. ğŸ˜¡  
AsÃ­ que decidÃ­ **cerrarlo y abrirlo en cada nueva pÃ¡gina**. Â¡FuncionÃ³! Ahora tenÃ­a **27 archivos CSV**, uno por cada pÃ¡gina de productos. ğŸ“‚âœ…  

### ğŸ† **Lo que aprendÃ­**  
âœ… A veces, lo mejor es **empezar desde cero y avanzar poco a poco**.  
âœ… **Observar patrones** en los datos puede hacerte la vida mÃ¡s fÃ¡cil.  
âœ… **Cada problema tiene una soluciÃ³n** (aunque implique reiniciar el navegador ğŸ”„).  

PrÃ³ximo paso: **unir los 27 CSV en un solo archivo** y prepararlo para **Power BI**. ğŸš€ğŸ“Š  

---

## CÃ³digo para la obtenciÃ³n de datos. 

<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-1.png" width="600" height="300">  

## ğŸ“¦ **MÃ³dulos importados en el scraper**  

Este bloque de cÃ³digo **importa todas las librerÃ­as necesarias** para el funcionamiento del scraper. ğŸ“¥ğŸ”  

### ğŸ› ï¸ **Â¿Para quÃ© sirve cada una?**  

#### â³ **Manejo del tiempo**  
- `import time` â†’ Permite **pausar la ejecuciÃ³n** del cÃ³digo en momentos clave.  

#### ğŸ“„ **Manejo de archivos CSV y texto**  
- `import csv` â†’ Para **guardar los datos extraÃ­dos** en archivos CSV.  
- `import re` â†’ **Expresiones regulares**, Ãºtil para limpiar y estructurar texto.  
- `import unidecode` â†’ **Elimina acentos y caracteres especiales**, Ãºtil para URLs.  

#### ğŸ“‚ **Manejo del sistema de archivos**  
- `import os` â†’ Permite **crear directorios y manejar rutas de archivos**.  

#### ğŸŒ **AutomatizaciÃ³n del navegador con Selenium**  
- `from selenium import webdriver` â†’ Para **controlar el navegador web**.  
- `from selenium.webdriver.chrome.service import Service` â†’ Gestiona **el servicio de ChromeDriver**.  
- `from selenium.webdriver.chrome.options import Options` â†’ Configura **opciones avanzadas del navegador**.  
- `from selenium.webdriver.common.by import By` â†’ Facilita **la bÃºsqueda de elementos en la web**.  
- `from selenium.webdriver.support.ui import WebDriverWait` â†’ Permite **esperar a que aparezcan elementos en la pÃ¡gina**.  
- `from selenium.webdriver.support import expected_conditions as EC` â†’ Define **condiciones especÃ­ficas para esperar elementos** (ejemplo: "cuando un botÃ³n sea clickeable").  

---

<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-2.png" width="600" height="300">  

## ğŸ–¥ï¸ **Clase `PCScraper`**

Esta clase define el **scraper** encargado de extraer informaciÃ³n de ratones en **PCComponentes** ğŸ­ğŸ›’.

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**

1. **Define el `chromedriver.exe` como controlador del navegador** ğŸï¸  
   - El parÃ¡metro `driver_path="chromedriver.exe"` establece **la ruta del driver de Chrome** para automatizar la navegaciÃ³n.  
   - Esto permite que Selenium **controle el navegador y acceda a las pÃ¡ginas de productos**.  

2. **Genera un diccionario con todas las URLs de las pÃ¡ginas** ğŸŒ  
   - `self.category_urls` almacena un diccionario donde:  
     - La **clave** es el identificador de la pÃ¡gina (`ratones_p1`, `ratones_p2`, etc.).  
     - El **valor** es la **URL completa** de cada pÃ¡gina de productos.  
   - Usa **un bucle con `range(1, 29)`**, generando automÃ¡ticamente **las 28 pÃ¡ginas** de resultados.  

3. **Guarda la ruta del controlador y la URL base** ğŸ”—  
   - `self.driver_path = driver_path` almacena la ubicaciÃ³n del **ChromeDriver**.  
   - `self.base_url = "https://www.pccomponentes.com/"` establece la **URL base de la tienda**.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-3.png" width="600" height="300">  

## ğŸŒ **FunciÃ³n `start_driver`**

Esta funciÃ³n **inicia una nueva sesiÃ³n del navegador Chrome** con configuraciones personalizadas para **optimizar el scraping** y **evitar bloqueos**. ğŸï¸ğŸ’¨  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Crea una configuraciÃ³n especial para el navegador** âš™ï¸  
   - `chrome_options = Options()` inicializa un objeto para **definir opciones avanzadas de Chrome**.  
   - `chrome_options.add_argument("--start-maximized")` hace que el navegador **se inicie en pantalla completa**, lo que **reduce errores de carga y mejora la visibilidad de los elementos**.  

2ï¸âƒ£ **Evita la detecciÃ³n como bot** ğŸ•µï¸â€â™‚ï¸  
   - `chrome_options.add_argument("user-agent=Mozilla/...")` cambia el **User-Agent** del navegador.  
   - Simula que la peticiÃ³n proviene de un usuario real en lugar de un bot, lo que **disminuye la probabilidad de ser bloqueado** por la web.  

3ï¸âƒ£ **Inicia el navegador con la configuraciÃ³n establecida** ğŸš€  
   - `self.driver = webdriver.Chrome(service=Service(self.driver_path), options=chrome_options)`  
   - **Se usa `Service(self.driver_path)`** para asegurarse de que el controlador **ChromeDriver** funcione correctamente.  
   - Todas las opciones configuradas se aplican para garantizar **una navegaciÃ³n fluida y sin detecciÃ³n**.  

---


<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-4.png" width="600" height="300">  

## âŒ **FunciÃ³n `close_driver`**  

Esta funciÃ³n **cierra el navegador** una vez que el scraping ha terminado, asegurando que los recursos del sistema se liberen correctamente. ğŸŒğŸ”š  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Cierra la sesiÃ³n del navegador** ğŸ  
   - `self.driver.quit()` **cierra completamente la ventana de Chrome**, finalizando la sesiÃ³n de Selenium.  
   - Esto **libera memoria y evita que queden procesos abiertos** innecesariamente.  

---


<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-5.png" width="600" height="300">  

## ğŸª **FunciÃ³n `accept_cookies`**  

Esta funciÃ³n **acepta las cookies automÃ¡ticamente** si el botÃ³n estÃ¡ presente en la pÃ¡gina, evitando interrupciones durante el scraping. ğŸŒğŸ”˜  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Espera a que el botÃ³n de aceptar cookies estÃ© disponible** â³  
   - Usa `WebDriverWait(self.driver, 5).until(EC.element_to_be_clickable((By.ID, 'cookiesAcceptAll')))` para **esperar hasta 5 segundos** a que el botÃ³n sea clickeable.  

2ï¸âƒ£ **Hace clic en el botÃ³n de aceptaciÃ³n** ğŸ‘†  
   - Si el botÃ³n se encuentra, `accept_button.click()` lo presiona automÃ¡ticamente.  
   - `time.sleep(2)` agrega una pequeÃ±a pausa de **2 segundos** para asegurar que el clic se registre correctamente.  

3ï¸âƒ£ **Manejo de errores** âš ï¸  
   - Si el botÃ³n **no aparece o las cookies ya fueron aceptadas**, **se captura la excepciÃ³n**.  
   - Muestra el mensaje `"ğŸ”¹ No se encontrÃ³ el botÃ³n de cookies o ya fueron aceptadas."`, permitiendo que el cÃ³digo **siga ejecutÃ¡ndose sin problemas**.  

---

<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-6.png" width="600" height="300">  

## ğŸ”— **FunciÃ³n `generate_url`**  

Esta funciÃ³n **genera una URL vÃ¡lida** para un producto a partir de su nombre, asegurÃ¡ndose de que tenga el formato adecuado para ser usada en la web. ğŸŒğŸ”„  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Elimina caracteres especiales y acentos** âœ‚ï¸  
   - `unidecode.unidecode(product_name)` convierte caracteres con acentos (ej. `CÃ¡mara`) a su equivalente sin acento (`Camara`).  
   - Esto **garantiza compatibilidad con URLs**, evitando caracteres invÃ¡lidos.  

2ï¸âƒ£ **Filtra caracteres no deseados** ğŸ”  
   - `re.sub(r'[^a-zA-Z0-9\s]', '', clean_name)` elimina **todo lo que no sea letras, nÃºmeros o espacios**.  
   - AsÃ­ se evita que caracteres especiales rompan la URL.  

3ï¸âƒ£ **Convierte el texto a minÃºsculas y reemplaza espacios** ğŸ”¤  
   - `clean_name.lower()` transforma el texto a **minÃºsculas** para mantener consistencia.  
   - `.replace(" ", "-")` reemplaza los espacios por guiones (`-`), que son estÃ¡ndar en URLs.  

4ï¸âƒ£ **Genera la URL final** ğŸ”—  
   - `return f"{self.base_url}{clean_name}"` une la **URL base** con el nombre limpio del producto.  
   - Por ejemplo, si `product_name = "RatÃ³n Ã“ptico Gamer"`, la salida serÃ¡:  
     ```
     https://www.pccomponentes.com/raton-optico-gamer
     ```  
--- 


<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-7.png" width="2000" height="1000">  

## ğŸ›’ **FunciÃ³n `scrape_category`**  

Esta funciÃ³n **extrae los datos de una sola pÃ¡gina de una categorÃ­a especÃ­fica** dentro de la tienda online. ğŸ“¦ğŸ”  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Inicia el navegador** ğŸŒ  
   - `self.start_driver()` abre una nueva ventana de Chrome para realizar el scraping.  
   - Se asegura de que el navegador **estÃ© configurado correctamente** antes de comenzar.  

2ï¸âƒ£ **Carga la pÃ¡gina de la categorÃ­a** ğŸ”—  
   - `self.driver.get(category_url)` accede a la URL de la categorÃ­a que se quiere analizar.  
   - AquÃ­ es donde estarÃ¡n **todos los productos de esa categorÃ­a**.  

3ï¸âƒ£ **Acepta las cookies si es necesario** ğŸª  
   - `self.accept_cookies()` busca y **hace clic en el botÃ³n de aceptar cookies** si aparece.  
   - Evita que este aviso bloquee la ejecuciÃ³n del scraper.  

### â³ **Esperando la carga de productos en `scrape_category`**  

Esta parte de la funciÃ³n **espera a que los productos de la categorÃ­a se carguen completamente** antes de extraerlos. ğŸ“ŠğŸ•µï¸â€â™‚ï¸  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Espera a que aparezcan los productos** â³  
   - `WebDriverWait(self.driver, 15).until(EC.presence_of_element_located(...))`  
   - **Se espera hasta 15 segundos** para que al menos un producto cargue correctamente.  
   - Busca un `h3.product-card__title`, que es el **tÃ­tulo del producto** en la pÃ¡gina.  

2ï¸âƒ£ **AÃ±ade una pausa extra** âŒ›  
   - `time.sleep(5)` da **5 segundos adicionales** para asegurarse de que **todos los elementos de la pÃ¡gina estÃ©n listos**.  
   - Esto ayuda a evitar errores si el contenido se carga lentamente.  

3ï¸âƒ£ **Extrae la lista de productos** ğŸ›ï¸  
   - `products = self.driver.find_elements(By.CSS_SELECTOR, "div.product-card")`  
   - Encuentra **todos los productos** en la pÃ¡gina, cada uno dentro de un `div.product-card`.  
   - Guarda estos elementos en la lista `products`.  

4ï¸âƒ£ **Prepara la lista de datos** ğŸ“‹  
   - `product_data = []` crea una lista vacÃ­a donde **se guardarÃ¡ la informaciÃ³n de cada producto**.  
   - En los siguientes pasos, se extraerÃ¡n detalles como **nombre, precio, valoraciones, etc.** y se guardarÃ¡n aquÃ­.  

### ğŸ›ï¸ **ExtracciÃ³n de datos de los productos**  

Esta parte de la funciÃ³n **recorre todos los productos de la categorÃ­a** y extrae informaciÃ³n clave como el **nombre, URL y precio**. ğŸ·ï¸ğŸ’°  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Recorre todos los productos encontrados** ğŸ”„  
   - `for product in products:` itera sobre **cada producto en la lista `products`**.  
   - Cada **`product`** representa un artÃ­culo en la pÃ¡gina.  

2ï¸âƒ£ **Extrae el nombre del producto** ğŸ“  
   - `name = product.find_element(By.CSS_SELECTOR, "h3.product-card__title").text.strip()`  
   - Busca el **tÃ­tulo del producto** dentro de la tarjeta (`product-card`).  
   - Usa `.strip()` para **eliminar espacios extra** antes y despuÃ©s del texto.  
   - Si el tÃ­tulo **no estÃ¡ disponible**, asigna `"No disponible"`.  

3ï¸âƒ£ **Genera la URL del producto automÃ¡ticamente** ğŸ”—  
   - `url = self.generate_url(name)`  
   - Llama a la funciÃ³n `generate_url(name)` para **crear una URL vÃ¡lida basada en el nombre**.  
   - Reemplaza espacios y caracteres especiales para que la URL sea compatible con la web.  

4ï¸âƒ£ **Extrae el precio del producto** ğŸ’²  
   - `price = product.find_element(By.CSS_SELECTOR, "span[data-e2e='price-card']").text.strip()`  
   - Busca el precio dentro de un `span` con el atributo `data-e2e='price-card'`.  
   - Si el precio **no estÃ¡ disponible**, asigna `"No disponible"`. 

### â­ **ExtracciÃ³n de Valoraciones y Opiniones**  

Esta parte de la funciÃ³n **extrae la valoraciÃ³n (rating) y el nÃºmero de opiniones** de cada producto, asegurÃ¡ndose de que la informaciÃ³n se capture correctamente. ğŸ“ŠğŸ”  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Inicializa valores predeterminados** ğŸ”„  
   - `rating = "No disponible"` y `opinions = "0"` aseguran que si no se encuentra informaciÃ³n, **no haya valores vacÃ­os**.  

2ï¸âƒ£ **Verifica si el producto tiene valoraciones** â­  
   - `rating_container = product.find_element(By.CSS_SELECTOR, ".product-card__rating-container")`  
   - Busca el **contenedor de valoraciones** dentro de la tarjeta del producto.  
   - Si no existe, el cÃ³digo **continÃºa sin errores**.  

3ï¸âƒ£ **Extrae la valoraciÃ³n numÃ©rica del producto** ğŸ”¢  
   - Se buscan `span` dentro del `rating_container`.  
   - Se analiza cada `span.text` para detectar patrones como `4.5/5` o `4,5/5`.  
   - Usa `re.search(r'[0-9][.,][0-9]/[0-9]', text)` para identificar formatos vÃ¡lidos.  
   - Si se encuentra, se guarda en `rating` y se detiene la bÃºsqueda.  

4ï¸âƒ£ **Extrae el nÃºmero de opiniones** ğŸ’¬  
   - Busca palabras clave como `"opiniÃ³n"` dentro del contenedor de valoraciones.  
   - Extrae el primer nÃºmero encontrado (`\d+`) y lo asigna a `opinions`.  
   - Si no hay opiniones visibles, el valor **permanece en "0"**.  

5ï¸âƒ£ **Manejo de errores** âš ï¸  
   - Si el contenedor de valoraciones **no existe**, el cÃ³digo **sigue sin fallar**.  
   - Se usa `try-except` en varios niveles para **evitar que errores en una parte bloqueen la ejecuciÃ³n completa**.  

### ğŸ“‹ **Almacenamiento de Datos y Manejo de Errores**  

Esta Ãºltima parte de la funciÃ³n **guarda los datos extraÃ­dos en una lista y maneja posibles errores**, asegurando que el scraping se complete correctamente. ğŸ“Šâœ…  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Guarda los datos en una lista** ğŸ“‚  
   - `product_data.append([name, price, rating, opinions, url])`  
   - **Cada producto** se almacena como una lista con los siguientes valores:  
     - ğŸ“Œ `name` â†’ Nombre del producto.  
     - ğŸ’² `price` â†’ Precio actual.  
     - â­ `rating` â†’ ValoraciÃ³n promedio.  
     - ğŸ’¬ `opinions` â†’ NÃºmero de opiniones.  
     - ğŸ”— `url` â†’ Enlace al producto.  
   - Esto permite que todos los datos queden organizados y listos para su uso posterior (ej. guardado en CSV o base de datos).  

2ï¸âƒ£ **Manejo de errores en productos individuales** âš   
   - `except Exception as e:` captura cualquier **error durante la extracciÃ³n de un producto**.  
   - Si un producto falla, muestra el mensaje `âš  Error extrayendo datos de un producto: {e}`.  
   - **El resto de los productos se siguen procesando sin interrupciones**.  

3ï¸âƒ£ **Devuelve la lista de productos extraÃ­dos** âœ…  
   - `return product_data` devuelve **todos los datos recopilados** en la categorÃ­a actual.  
   - Si no se encuentran productos, se devuelve una **lista vacÃ­a** `[]`.  

4ï¸âƒ£ **Manejo de errores en toda la categorÃ­a** âŒ  
   - Si hay un error **en toda la pÃ¡gina**, lo captura `except Exception as e:`.  
   - Muestra `âŒ Error al obtener los productos de {category_url}: {e}` para indicar quÃ© fallÃ³.  
   - En este caso, tambiÃ©n devuelve `[]`, asegurando que el scraper no se detenga completamente.  

5ï¸âƒ£ **Cierra el navegador al finalizar** ğŸŒğŸ”š  
   - `finally: self.close_driver()`  
   - **Se cierra el navegador en todos los casos**, ya sea que la extracciÃ³n haya sido exitosa o haya ocurrido un error.  
   - Esto evita **consumo innecesario de recursos** y posibles bloqueos en futuras ejecuciones.  

---


<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-8.png" width="600" height="300">  


### ğŸ“‚ **FunciÃ³n `scrape_all_categories`**  

Esta funciÃ³n **recorre todas las pÃ¡ginas de productos de la categorÃ­a y guarda los datos en archivos CSV separados**. ğŸ“ŠğŸ›ï¸  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Recorre todas las categorÃ­as disponibles** ğŸ”„  
   - `for category_name, category_url in self.category_urls.items():`  
   - Itera sobre el **diccionario `self.category_urls`**, que contiene los nombres y URLs de cada categorÃ­a.  

2ï¸âƒ£ **Llama a la funciÃ³n `scrape_category` para extraer los productos** ğŸ›’  
   - `product_data = self.scrape_category(category_name, category_url)`  
   - Llama a la funciÃ³n `scrape_category` para **extraer los productos de la pÃ¡gina actual**.  
   - Si la categorÃ­a **tiene productos**, se procede a guardarlos.  

3ï¸âƒ£ **Guarda los datos en un archivo CSV** ğŸ’¾  
   - **Genera un nombre de archivo** basado en la categorÃ­a:  
     ```python
     csv_filename = f"{category_name}.csv"
     ```
   - **Abre el archivo CSV en modo escritura (`"w"`)**, asegurando que se cree desde cero.  
   - **Escribe los encabezados** en la primera fila:  
     - ğŸ“Œ `Nombre del Producto`  
     - ğŸ’² `Precio`  
     - â­ `Valoraciones`  
     - ğŸ’¬ `Opiniones`  
     - ğŸ”— `URL`  
   - **Escribe los datos de los productos** fila por fila con `writer.writerows(product_data)`.  

4ï¸âƒ£ **Muestra un mensaje de Ã©xito** âœ…  
   - Indica cuÃ¡ntos productos se han guardado y en quÃ© archivo CSV.  
   - Ejemplo de salida:  
     ```
     âœ… Se han guardado 50 productos en 'ratones_p1.csv'.
     ```

5ï¸âƒ£ **Espera 5 segundos antes de continuar con la siguiente pÃ¡gina** â³  
   - `time.sleep(5)`  
   - **Evita que el scraper sea detectado como bot**, simulando un comportamiento humano.  

---


<img src="Imagenes/PCCOMPONENTES/Ratones-datos/imagen-9.png" width="600" height="300">  


## ğŸ **EjecuciÃ³n del Scraper**  

Este bloque de cÃ³digo **pone en marcha el scraper**, iniciando el proceso de extracciÃ³n de datos de todas las categorÃ­as. ğŸš€ğŸ“Š  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Verifica que el script se estÃ¡ ejecutando directamente** â–¶ï¸  
   - `if __name__ == "__main__":`  
   - Este condicional asegura que el cÃ³digo **solo se ejecute si el script es ejecutado directamente**, y **no si es importado como mÃ³dulo** en otro archivo.  

2ï¸âƒ£ **Crea una instancia del scraper** ğŸ—ï¸  
   - `scraper = PCScraper()`  
   - Se inicializa un objeto de la clase `PCScraper`, que contiene toda la lÃ³gica de scraping.  
   - AquÃ­ se configuran **las URLs de las categorÃ­as y las opciones del navegador**.  

3ï¸âƒ£ **Ejecuta el scraping de todas las categorÃ­as** ğŸ”„  
   - `scraper.scrape_all_categories()`  
   - Llama a la funciÃ³n que **recorre todas las pÃ¡ginas de productos y guarda los datos en archivos CSV**.  
   - **Cada categorÃ­a se procesa de manera independiente**, asegurando que todas las pÃ¡ginas sean analizadas.  

---

# ğŸ¯ **ConclusiÃ³n del Apartado de ObtenciÃ³n de Datos**  

Hemos completado con Ã©xito el proceso de **extracciÃ³n de datos** con un scraper totalmente funcional. ğŸš€ğŸ“Š  

## âœ… **Â¿QuÃ© hemos logrado?**  

1ï¸âƒ£ **AutomatizaciÃ³n completa** ğŸ”„  
   - Desde **abrir el navegador** hasta **guardar los datos en archivos CSV**.  

2ï¸âƒ£ **ExtracciÃ³n eficiente** ğŸ“Š  
   - ObtenciÃ³n de **nombre del producto, precio, valoraciones, opiniones y URL**.  

3ï¸âƒ£ **Manejo de errores inteligente** âš ï¸  
   - **El scraper sigue funcionando** incluso si algunos datos no estÃ¡n disponibles.  

4ï¸âƒ£ **OptimizaciÃ³n anti-detecciÃ³n** ğŸ•µï¸â€â™‚ï¸  
   - **User-Agent personalizado** para evitar bloqueos.  
   - **Pausas estratÃ©gicas** para simular un usuario real.  

5ï¸âƒ£ **Datos listos para anÃ¡lisis** ğŸ“‚  
   - Todos los productos se han almacenado en **archivos CSV organizados**.  
   - **Perfecto para su visualizaciÃ³n en Power BI u otras herramientas de anÃ¡lisis**.  

---

## 3. Limpieza de datos (eliminaciÃ³n de nulos y datos errÃ³neos, etc.). DescripciÃ³n de los datos. Se debe dar una descripciÃ³n completa de los datos indicando quÃ© significa cada uno de los atributos.

# ğŸ§¹ **Limpieza de Datos**  

El proceso de limpieza de datos en este proyecto es **sencillo pero esencial** para garantizar que la informaciÃ³n extraÃ­da sea **relevante y precisa**. ğŸš€ğŸ“Š  

---

## ğŸ¯ **Â¿QuÃ© limpiaremos?**  

ğŸ”¹ **ImÃ¡genes duplicadas y no relevantes** ğŸ–¼ï¸  
   - Se han detectado **imÃ¡genes promocionales** que **se repiten en el mismo orden** para ratones, teclados y portÃ¡tiles.  
   - Estas imÃ¡genes **usan la misma clase (`class`) que las imÃ¡genes de productos**, por lo que se han incluido accidentalmente en la extracciÃ³n.  

ğŸ”¹ **Filtrado de imÃ¡genes segÃºn patrones** ğŸ”  
   - Dado que **las imÃ¡genes promocionales siguen un patrÃ³n especÃ­fico**, se pueden **identificar y eliminar fÃ¡cilmente**.  
   - Aunque el cÃ³digo varÃ­a ligeramente entre categorÃ­as (**ratones, teclados, portÃ¡tiles**), la lÃ³gica **es la misma** en todos los casos.  

---

## ğŸ› ï¸ **Â¿CÃ³mo se hace la limpieza?**  

1ï¸âƒ£ **IdentificaciÃ³n de imÃ¡genes no deseadas**  
   - Se analizan **los patrones de repeticiÃ³n** en las imÃ¡genes extraÃ­das.  
   - Se detectan aquellas que corresponden a **banners publicitarios o contenido promocional**.  

2ï¸âƒ£ **Filtrado automÃ¡tico en el cÃ³digo**  
   - Se implementa una lÃ³gica que **excluye las imÃ¡genes** basÃ¡ndose en su posiciÃ³n o en atributos especÃ­ficos.  
   - Si una imagen **coincide con el patrÃ³n promocional**, **se descarta antes de almacenarla**.  

3ï¸âƒ£ **Mantenimiento de la calidad de datos**  
   - Solo se conservan **imÃ¡genes relevantes de los productos reales**.  
   - Se evita la presencia de contenido duplicado en la base de datos.  

---

## ğŸ”¥ **Â¿Por quÃ© es importante este proceso?**  

âœ… **Elimina imÃ¡genes irrelevantes**, manteniendo el dataset limpio.  
âœ… **Evita duplicados**, mejorando la calidad de los datos.    

---

<img src="Imagenes/PCCOMPONENTES/Limpieza de datos/imagen-1.png" width="600" height="300">  


# ğŸ—‘ï¸ **EliminaciÃ³n de ImÃ¡genes No Deseadas**  

Este cÃ³digo **elimina imÃ¡genes repetidas o no relevantes** dentro de la carpeta de portÃ¡tiles, asegurando que solo se mantengan las imÃ¡genes Ãºtiles. ğŸ–¼ï¸ğŸš®  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Define la carpeta principal** ğŸ“‚  
   - `main_folder = "imagenes_portatiles"`  
   - AquÃ­ es donde se encuentran las subcarpetas con las imÃ¡genes almacenadas.  

2ï¸âƒ£ **Lista de archivos a eliminar** âŒ  
   - `files_to_delete = {"image"}`  
   - Se crea un **conjunto** con los nombres de archivos que deben ser eliminados.  
   - En este caso, cualquier archivo llamado `"image"` serÃ¡ **borrado automÃ¡ticamente**.  

3ï¸âƒ£ **Recorre todas las subcarpetas** ğŸ”„  
   - Usa `os.walk(main_folder)` para **iterar sobre cada subcarpeta** dentro de `imagenes_portatiles`.  
   - En cada subcarpeta, **verifica los archivos almacenados**.  

4ï¸âƒ£ **Elimina archivos innecesarios** ğŸ—‘ï¸  
   - Si un archivo coincide con un nombre en `files_to_delete`, se borra usando `os.remove(file_path)`.  
   - Se muestra un mensaje confirmando cada eliminaciÃ³n con `print(f"Eliminado: {file_path}")`.  

5ï¸âƒ£ **Manejo de errores** âš ï¸  
   - Si ocurre un error al eliminar un archivo, se captura y muestra un mensaje de advertencia:  
     ```
     Error al eliminar <ruta_del_archivo>: <detalle_del_error>
     ```  
   - Esto evita que el cÃ³digo se detenga si hay problemas con permisos o archivos inexistentes.  

6ï¸âƒ£ **Finaliza el proceso** âœ…  
   - Al terminar, imprime `"Proceso completado."` indicando que la limpieza ha sido exitosa.  

ğŸ“Œ **Con esta limpieza, garantizamos que los datos extraÃ­dos sean Ãºtiles y sin ruido.**  

# ğŸ”„ **ETL en AWS Glue: UnificaciÃ³n y TransformaciÃ³n de Datos**  

Ahora que los datos estÃ¡n listos, realizaremos un **proceso ETL (Extract, Transform, Load)** en **AWS Glue** para unir toda la informaciÃ³n y crear una nueva columna.  

---

## ğŸ› ï¸ **Â¿QuÃ© es una ETL?**  

ğŸ”¹ **ETL** significa **Extract, Transform, Load** (**Extraer, Transformar y Cargar**).  
ğŸ”¹ Es un proceso fundamental en **ingenierÃ­a de datos** que permite:  
   1. **Extract (ExtracciÃ³n):** Obtener datos desde mÃºltiples fuentes (**CSV, bases de datos, APIs, etc.**).  
   2. **Transform (TransformaciÃ³n):** Limpiar, unir, modificar y generar nuevas columnas.  
   3. **Load (Carga):** Guardar los datos transformados en un formato optimizado (**S3, Redshift, Power BI, etc.**).  

---

## ğŸš€ **ETL en AWS Glue con PySpark y Modo Visual**  

AWS Glue es un servicio **serverless** que permite **automatizar procesos ETL** con dos enfoques principales:  

ğŸ”¹ **Modo Visual (Similar a Spoon)** ğŸ–±ï¸  
   - Ofrece una **interfaz grÃ¡fica** donde se pueden **arrastrar y conectar componentes**.  
   - Es Ãºtil para tareas bÃ¡sicas, pero **tiene limitaciones en personalizaciÃ³n**.  

ğŸ”¹ **Modo CÃ³digo (PySpark)** ğŸ“  
   - Permite **personalizar transformaciones avanzadas** y trabajar con grandes volÃºmenes de datos.  
   - Es **mÃ¡s flexible**, ideal para procesos complejos.  

ğŸ”¹ **Nuestro Enfoque**  
   - **Trabajaremos en el modo visual hasta cierto punto** para facilitar la manipulaciÃ³n de datos.  
   - Luego, **cambiaremos a cÃ³digo (PySpark)** cuando necesitemos **guardar mÃºltiples archivos en uno solo**.  

---

## ğŸ¯ **Objetivo de nuestra ETL**  

âœ… **Unificar toda la informaciÃ³n** proveniente de diferentes archivos CSV.  
âœ… **Crear una nueva columna** con datos transformados.  
âœ… **Optimizar los datos y consolidarlos en un Ãºnico fichero** para su anÃ¡lisis en Power BI.  

---


<img src="Imagenes/ETL/imagen-1.png" width="600" height="300">  

# ğŸ› ï¸ **DiseÃ±o de la ETL en AWS Glue (Modo Visual)**  

La imagen muestra la configuraciÃ³n de una ETL en **AWS Glue Studio**, utilizando el **modo visual** para procesar los datos de un bucket de **Amazon S3**, transformarlos con **SQL Query** y almacenarlos nuevamente en **S3**.  

---

## ğŸ” **Estructura de la ETL en la imagen**  

1ï¸âƒ£ **Fuente de Datos: Amazon S3** ğŸ—„ï¸  
   - Se carga la informaciÃ³n desde un **bucket de S3**.  
   - Esto puede ser un conjunto de archivos **CSV, JSON u otro formato compatible**.  

2ï¸âƒ£ **TransformaciÃ³n: SQL Query** ğŸ”„  
   - Se aplica una transformaciÃ³n utilizando **SQL**.  
   - AquÃ­ se pueden **filtrar, modificar columnas o unir datasets**.  

3ï¸âƒ£ **Destino de Datos: Amazon S3** ğŸ“¤  
   - Los datos transformados se guardan en otro **bucket de S3**.  
   - En este caso, se ha seleccionado el formato **CSV** y se ha definido una ubicaciÃ³n especÃ­fica.  

---

## ğŸš€ **CÃ³mo deberÃ­a haber sido la ETL**  

ğŸ”¹ **El diseÃ±o visual permite realizar muchas operaciones de transformaciÃ³n**, pero tiene **limitaciones** cuando se requiere personalizaciÃ³n avanzada.  

ğŸ”¹ En nuestro caso, el **modo visual es Ãºtil hasta cierto punto**, pero **necesitamos cambiar a cÃ³digo (PySpark)** para:  
   - **Unir mÃºltiples archivos en uno solo**.  
   - **Aplicar transformaciones mÃ¡s flexibles** que no se pueden realizar con la interfaz visual.  
   - **Definir bien el formato** en el almacenamiento del S3.  

ğŸ“Œ **A continuaciÃ³n, explicaremos el cÃ³digo que reemplazarÃ¡ esta configuraciÃ³n para lograr la ETL completa en AWS Glue.** ğŸš€  

<img src="Imagenes/ETL/imagen-2.png" width="600" height="300">  

## ğŸš€ **Importaciones necesarias**  

Este cÃ³digo **prepara el entorno** para ejecutar una tarea en **AWS Glue**, una herramienta que ayuda a procesar datos de manera eficiente en la nube â˜ï¸ğŸ“Š.  

### ğŸ› ï¸ **Â¿QuÃ© hace cada lÃ­nea?**  

1. **Importa librerÃ­as esenciales** ğŸ“¦  
   - `sys`: Permite interactuar con el sistema operativo y gestionar argumentos.  
   - `awsglue.transforms`: Contiene funciones para transformar datos dentro de AWS Glue.  
   - `awsglue.utils.getResolvedOptions`: Sirve para obtener parÃ¡metros que se pasan al script desde AWS Glue.  

2. **Configura el entorno de ejecuciÃ³n en Spark** ğŸ”¥  
   - `SparkContext`: Crea el contexto de Spark, que es el motor que procesarÃ¡ los datos en paralelo.  
   - `GlueContext`: Un entorno especial de AWS Glue que facilita la integraciÃ³n con otros servicios de AWS.  
   - `Job`: Permite definir una **tarea en AWS Glue**, facilitando su ejecuciÃ³n y seguimiento.  

3. **EvalÃºa la calidad de los datos** âœ…  
   - `EvaluateDataQuality`: Un mÃ³dulo de AWS Glue que **verifica si los datos son correctos** y cumplen con ciertos estÃ¡ndares antes de seguir procesÃ¡ndolos.  

4. **Usa `DynamicFrame` en lugar de DataFrames tradicionales** ğŸ”„  
   - `DynamicFrame`: Una versiÃ³n mejorada de los DataFrames de Spark, diseÃ±ada para trabajar con datos en AWS Glue.  
   - Permite **manejar datos semiestructurados** y **hacer transformaciones fÃ¡cilmente** sin necesidad de definir un esquema fijo.  

---

<img src="Imagenes/ETL/imagen-3.png" width="600" height="300">     

## ğŸš€ **FunciÃ³n `sparkSqlQuery`**  

Esta funciÃ³n permite **ejecutar consultas SQL en datos almacenados en AWS Glue**. Es Ãºtil para **transformar y analizar los datos** sin necesidad de escribir cÃ³digo complejo, solo utilizando SQL. ğŸ“ŠğŸ’¡  

### ğŸ” **Â¿CÃ³mo funciona?**  

1. **Recibe los siguientes parÃ¡metros** ğŸ“¥  
   - ğŸ—ï¸ `glueContext`: Proporciona acceso a AWS Glue y su integraciÃ³n con Spark.  
   - ğŸ“œ `query`: La consulta SQL que se aplicarÃ¡ a los datos.  
   - ğŸ”„ `mapping`: Un diccionario donde **las claves son nombres de tablas temporales** y **los valores son `DynamicFrame` con los datos a procesar**.  
   - ğŸ” `transformation_ctx`: Identificador que permite rastrear la transformaciÃ³n dentro de Glue.  

2. **Convierte los `DynamicFrame` en tablas temporales** ğŸ”„  
   - ğŸ“Œ **Recorre cada elemento en `mapping`**, extrayendo el alias (nombre de la tabla) y los datos (`DynamicFrame`).  
   - ğŸ—‚ï¸ **Transforma cada `DynamicFrame` en un `DataFrame` de Spark** para poder consultarlo con SQL.  
   - ğŸ·ï¸ **Crea una tabla temporal** (`createOrReplaceTempView(alias)`) para que la consulta SQL pueda referirse a ella.  

3. **Ejecuta la consulta SQL sobre los datos** âš¡  
   - ğŸ“Š Utiliza `spark.sql(query)` para aplicar la transformaciÃ³n deseada.  

4. **Convierte el resultado en un `DynamicFrame` nuevamente** ğŸ”„  
   - âœ¨ `DynamicFrame.fromDF(result, glueContext, transformation_ctx)`:  
     - **Toma los datos procesados** y los **devuelve en formato `DynamicFrame`**.  
     - Esto permite **seguir aplicando transformaciones** en AWS Glue sin problemas.  

---

<img src="Imagenes/ETL/imagen-4.png" width="600" height="300">  

## ğŸš€ **ConfiguraciÃ³n del Entorno en AWS Glue**  

Este fragmento de cÃ³digo **inicializa el entorno de ejecuciÃ³n en AWS Glue**, preparando Spark para procesar datos en la nube. ğŸŒâš¡  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1. **Obtiene los parÃ¡metros del trabajo en Glue** ğŸ“  
   - `args = getResolvedOptions(sys.argv, ['JOB_NAME'])`  
   - ğŸ” Extrae el nombre del trabajo desde los **argumentos que recibe el script** cuando se ejecuta en AWS Glue.  
   - ğŸ·ï¸ `JOB_NAME` es el identificador del trabajo dentro de AWS.  

2. **Inicializa Spark** ğŸ”¥  
   - `sc = SparkContext()`  
   - ğŸ—ï¸ Crea el **contexto de Spark**, necesario para ejecutar tareas de procesamiento de datos en paralelo.  

3. **Crea el contexto de AWS Glue** ğŸ› ï¸  
   - `glueContext = GlueContext(sc)`  
   - ğŸ”„ Permite que AWS Glue utilice Spark para transformar y manejar datos de forma eficiente.  
   - ğŸ“¡ **Facilita la conexiÃ³n con otras herramientas de AWS** como S3, Redshift o DynamoDB.  

4. **Obtiene la sesiÃ³n de Spark** ğŸš€  
   - `spark = glueContext.spark_session`  
   - ğŸ–¥ï¸ **Crea una sesiÃ³n de Spark**, que es necesaria para ejecutar consultas y manipular datos.  

5. **Inicializa el trabajo en Glue** âœ…  
   - `job = Job(glueContext)`  
   - ğŸ—ï¸ Crea una **instancia de trabajo en AWS Glue**, permitiendo **controlar su ejecuciÃ³n y finalizarlo correctamente**.  
   - `job.init(args['JOB_NAME'], args)`:  
     - ğŸ·ï¸ **Inicia el trabajo** con el nombre que se obtuvo en el primer paso.  
     - ğŸ“‹ **Permite que AWS Glue rastree y administre el estado del trabajo.**  

---

<img src="Imagenes/ETL/imagen-5.png" width="600" height="300">  

## ğŸ“ **Reglas por Defecto para la Calidad de Datos**  

Este fragmento define un **conjunto de reglas bÃ¡sicas** que AWS Glue utilizarÃ¡ para **validar la calidad de los datos** antes de procesarlos. âœ…ğŸ“Š  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1. **Define un conjunto de reglas de calidad de datos** ğŸ“œ  
   - Se almacena en la variable `DEFAULT_DATA_QUALITY_RULESET`.  
   - ğŸ” Contiene un conjunto de reglas que AWS Glue **aplicarÃ¡ automÃ¡ticamente** a todos los nodos de destino que tengan habilitada la validaciÃ³n de calidad de datos.  

2. **Reglas establecidas** âš–ï¸  
   - `ColumnCount > 0`  
   - ğŸ“Œ **Verifica que la tabla tenga al menos una columna**.  
   - ğŸ”„ **Evita procesar datos vacÃ­os o estructuras incorrectas** que podrÃ­an causar errores mÃ¡s adelante.  

---

<img src="Imagenes/ETL/imagen-5.png" width="600" height="300">  

## â˜ï¸ **Carga de Datos desde Amazon S3**  

Este fragmento de cÃ³digo **lee un archivo CSV almacenado en Amazon S3** y lo convierte en un `DynamicFrame` para su procesamiento en AWS Glue. ğŸ“‚ğŸ’¡  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1. **Configura la lectura de datos desde S3** ğŸ“¥  
   - `AmazonS3_node1740744770173 = glueContext.create_dynamic_frame.from_options(...)`  
   - ğŸ”„ **Convierte los datos en un `DynamicFrame`**, que es un formato optimizado para AWS Glue.  

2. **Define las opciones de formato** ğŸ—‚ï¸  
   - `format_options={"quoteChar": "\"", "withHeader": True, "separator": ","}`  
   - ğŸ·ï¸ `quoteChar`: Usa `"` para manejar valores entre comillas.  
   - ğŸ·ï¸ `withHeader`: Indica que el CSV tiene una fila de encabezados.  
   - ğŸ·ï¸ `separator`: Especifica que las columnas estÃ¡n separadas por comas (`,`).  

3. **Especifica la fuente de datos** ğŸŒ  
   - `connection_type="s3"`: Indica que los datos provienen de un **bucket de Amazon S3**.  
   - `connection_options={"paths": ["s3://inervisionai"], "recurse": True}`  
     - ğŸ“Œ **Ruta del bucket**: `s3://inervisionai`.  
     - ğŸ”„ `recurse=True`: Permite leer archivos dentro de subcarpetas.  

4. **Asigna un identificador al proceso de transformaciÃ³n** ğŸ”  
   - `transformation_ctx="AmazonS3_node1740744770173"`  
   - ğŸ—ï¸ AWS Glue usa este identificador para rastrear y organizar las transformaciones aplicadas al `DynamicFrame`.  

---

## ğŸ–¥ï¸ **Consulta SQL para ClasificaciÃ³n de Marcas**  

Este fragmento de cÃ³digo SQL **clasifica los productos segÃºn su marca** ğŸ·ï¸. La consulta revisa el nombre de cada producto y asigna una marca especÃ­fica si detecta ciertas palabras clave.  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1. **Selecciona todas las columnas del dataset** ğŸ“Š  
   - `SELECT *,`  
   - ğŸ”„ Mantiene todos los datos originales del conjunto de datos (`myDataSource`).  

2. **Crea una nueva columna llamada `Marca`** ğŸ·ï¸  
   - `CASE WHEN lower(Nombre del Producto) LIKE '%logitech%' THEN 'Logitech'`  
   - ğŸ” **Convierte el nombre del producto a minÃºsculas** (`lower(Nombre del Producto)`) para evitar problemas con mayÃºsculas/minÃºsculas.  
   - ğŸ” Si el nombre del producto contiene `"logitech"`, asigna la marca `"Logitech"`.  
   - ğŸ·ï¸ Este mismo proceso se repite para otras marcas como **Razer, Corsair, Asus, MSI, Apple, etc.**  

3. **Si el producto no coincide con ninguna marca conocida** â“  
   - `ELSE 'Otra'`  
   - ğŸ·ï¸ Si el producto **no pertenece a ninguna marca listada**, se le asigna la categorÃ­a `"Otra"`.  

4. **Aplica la consulta sobre la fuente de datos** ğŸ’¾  
   - `FROM myDataSource;`  
   - ğŸ“Œ `myDataSource` es el nombre de la tabla o `DynamicFrame` que contiene los datos originales.  

---

<img src="Imagenes/ETL/imagen-7.png" width="600" height="300">  

## ğŸš€ **EjecuciÃ³n de Consulta SQL y Almacenamiento en Amazon S3**  

Este fragmento de cÃ³digo **ejecuta una consulta SQL en los datos, transforma el resultado y lo guarda en un archivo CSV en Amazon S3**. ğŸ“Šâ˜ï¸  

### ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1. **Ejecuta la consulta SQL sobre los datos de Amazon S3** ğŸ–¥ï¸  
   - Se usa la funciÃ³n `sparkSqlQuery` para ejecutar la consulta SQL almacenada en `SqlQuery0`.  
   - Los datos provienen de `AmazonS3_node1740744770173` y se asigna un alias (`myDataSource`) para facilitar la consulta.  
   - El resultado de la consulta se guarda en `SQLQuery_node1740745043008`, que serÃ¡ utilizado en los siguientes pasos.  

2. **Convierte el resultado en un `DataFrame` de Spark** ğŸ”„  
   - Se transforma el `DynamicFrame` resultante de la consulta en un `DataFrame` para poder manipular los datos con mayor facilidad.  

3. **Verifica si hay datos antes de continuar** â—  
   - Antes de escribir en Amazon S3, se comprueba que el `DataFrame` no estÃ© vacÃ­o.  
   - Si no hay datos, se genera un error (`ValueError`) y el proceso se detiene para evitar archivos vacÃ­os en S3.  

4. **Reduce el nÃºmero de particiones para generar un solo archivo CSV** ğŸ“‚  
   - Se reorganizan los datos en una Ãºnica particiÃ³n para que Spark genere un solo archivo CSV en lugar de mÃºltiples fragmentos.  

5. **Muestra el esquema y algunas filas para depuraciÃ³n** ğŸ”  
   - Se imprime la estructura de las columnas del `DataFrame` para verificar su formato.  
   - Se muestran las primeras cinco filas para comprobar que los datos se han procesado correctamente.  

6. **Guarda el resultado en Amazon S3 en formato CSV** â˜ï¸  
   - Se escribe el `DataFrame` en Amazon S3 en formato CSV con sobrescritura activada, lo que significa que si el archivo ya existe, se reemplazarÃ¡.  
   - Se incluye la opciÃ³n de encabezados para que el archivo CSV mantenga los nombres de las columnas.  

7. **Confirma que el trabajo ha finalizado** âœ…  
   - Se ejecuta el comando `job.commit()`, lo que indica que el trabajo en AWS Glue ha finalizado correctamente.  

---


## 4. ExploraciÃ³n y visualizaciÃ³n de los datos. Se realizarÃ¡ un estudio de los datos buscando correlaciones, mostrando grÃ¡ficas de diferente tipologÃ­a, observando si hay valores nulos, etc.




# ğŸ–¼ï¸ **Almacenamiento de ImÃ¡genes en CSV**  

DespuÃ©s de eliminar las imÃ¡genes no deseadas, el siguiente paso es **registrarlas en un archivo CSV**. ğŸ“‚ğŸ”„  

## ğŸ¯ **Â¿Por quÃ© guardar las imÃ¡genes en un CSV?**  

ğŸ”¹ **OrganizaciÃ³n** â†’ Permite estructurar los datos para su fÃ¡cil anÃ¡lisis.  
ğŸ”¹ **IntegraciÃ³n con Power BI** â†’ Facilita la vinculaciÃ³n con otros datos, como precios o valoraciones.  
ğŸ”¹ **Accesibilidad** â†’ Un CSV es ligero y compatible con mÃºltiples herramientas de anÃ¡lisis.  

---

 <img src="Imagenes/Limpieza de datos/imagen-2.png" width="600" height="300">  

# ğŸ“‚ **DefiniciÃ³n de Carpetas y Lista de Datos**  

Antes de procesar las imÃ¡genes, es necesario **definir las carpetas de origen** y **crear una lista para almacenar la informaciÃ³n** extraÃ­da. ğŸ–¼ï¸ğŸ“Š  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona esta parte del cÃ³digo?**  

1ï¸âƒ£ **Definir las carpetas donde estÃ¡n las imÃ¡genes** ğŸ“‚  
   - `carpetas_principales = ["../../ikea_muebles/sillas"]`  
   - Se establece una lista con **las rutas de las carpetas principales**, donde se encuentran las imÃ¡genes organizadas en subcarpetas.  
   - En este caso, se estÃ¡ procesando la carpeta `"sillas"` dentro de `"ikea_muebles"`.  

2ï¸âƒ£ **Crear una lista para almacenar los datos** ğŸ“  
   - `data = []`  
   - Se inicializa una **lista vacÃ­a** que **almacenarÃ¡ la informaciÃ³n de cada imagen**.  
   - Posteriormente, en esta lista se guardarÃ¡n datos como:  
     - ğŸ–¼ï¸ `Nombre del archivo`  
     - ğŸ“‚ `Ruta de la imagen`  
     - ğŸ”  `Imagen codificada en base64`  

---

<img src="Imagenes/Limpieza de datos/imagen-3.png" width="600" height="300">  


# ğŸ–¼ï¸ **FunciÃ³n `procesar_carpeta`**  

Esta funciÃ³n **recorre carpetas y subcarpetas**, buscando imÃ¡genes, **convirtiÃ©ndolas a Base64** y almacenÃ¡ndolas en una lista con formato HTML. ğŸ“‚ğŸ“Š  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Recorre todas las carpetas y subcarpetas** ğŸ”„  
   - `os.walk(os.path.abspath(carpeta_raiz))`  
   - Convierte la **ruta relativa en absoluta** para evitar errores.  
   - **Recorre recursivamente** todas las carpetas y subcarpetas dentro de `carpeta_raiz`.  

2ï¸âƒ£ **Filtra archivos de imagen** ğŸ·ï¸  
   - `if archivo.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):`  
   - **Solo procesa archivos de imagen** con extensiones comunes.  
   - Ignora otros tipos de archivos no relevantes.  

3ï¸âƒ£ **Convierte la imagen a Base64** ğŸ”„  
   - `with open(ruta_imagen, "rb") as img_file:`  
   - Abre la imagen en **modo lectura binaria (`rb`)**.  
   - `base64.b64encode(img_file.read()).decode('utf-8')`  
   - **Codifica la imagen en Base64** y la convierte en un **string de texto**.  

4ï¸âƒ£ **Genera una etiqueta HTML con la imagen en Base64** ğŸ–¼ï¸  
   - `img_html = f'<img src="data:image/png;base64,{base64_str}" width="100"/>'`  
   - **Crea un fragmento HTML** que puede ser interpretado directamente en Power BI u otras herramientas.  
   - Se establece un **ancho de `100px`** para previsualizaciÃ³n.  

5ï¸âƒ£ **Agrega la imagen a la lista de datos** ğŸ“‹  
   - `data.append([img_html])`  
   - Guarda la informaciÃ³n en la lista `data`, para su posterior almacenamiento en CSV.  

6ï¸âƒ£ **Manejo de errores** âš ï¸  
   - Si ocurre algÃºn problema al procesar una imagen, el error **se muestra en consola** y el programa sigue ejecutÃ¡ndose.  

---

<img src="Imagenes/Limpieza de datos/imagen-4.png" width="600" height="300">  

# ğŸ“„ **ConversiÃ³n de ImÃ¡genes a CSV**  

DespuÃ©s de procesar todas las imÃ¡genes, este cÃ³digo **crea un DataFrame y lo guarda en un archivo CSV**, asegurando que estÃ© listo para su uso en Power BI u otras herramientas. ğŸ“‚ğŸ“Š  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Procesa todas las carpetas principales** ğŸ“‚  
   - `for carpeta in carpetas_principales:`  
   - **Recorre cada carpeta** y ejecuta `procesar_carpeta(carpeta)`.  
   - Se almacenan las imÃ¡genes **convertidas a Base64 con formato HTML** en la lista `data`.  

2ï¸âƒ£ **Crea un DataFrame con los datos** ğŸ—ï¸  
   - `df = pd.DataFrame(data, columns=["chair"])`  
   - Se genera un **DataFrame de Pandas** con una columna llamada `"chair"`.  
   - **Cada fila contiene una imagen en formato Base64 con etiqueta HTML**.  

3ï¸âƒ£ **Guarda el DataFrame en un archivo CSV** ğŸ’¾  
   - `csv_path = "chair.csv"` define el nombre del archivo.  
   - `df.to_csv(csv_path, index=False, encoding="utf-8-sig", quoting=csv.QUOTE_MINIMAL, escapechar="\\")`  
     - ğŸ”¹ **`index=False`** â†’ No guarda el Ã­ndice del DataFrame.  
     - ğŸ”¹ **`encoding="utf-8-sig"`** â†’ Asegura compatibilidad con **Power BI y Excel**.  
     - ğŸ”¹ **`quoting=csv.QUOTE_MINIMAL`** â†’ Evita problemas con comillas en los datos.  
     - ğŸ”¹ **`escapechar="\\ "`** â†’ Escapa caracteres especiales para evitar errores en la lectura del CSV.  

4ï¸âƒ£ **Muestra un mensaje de Ã©xito** âœ…  
   - `print(f"âœ… Archivo CSV guardado correctamente en: {csv_path}")`  
   - Confirma que el archivo se ha guardado **sin errores y listo para su anÃ¡lisis**.  

---
 
<img src="Imagenes/VisualizaciÃ³n_de_datos/imagen-1.png" width="600" height="300">

# ğŸ“¦ **ImportaciÃ³n de MÃ³dulos para la Prueba y VisualizaciÃ³n**  

Antes de verificar el correcto funcionamiento de los datos, necesitamos **importar las librerÃ­as necesarias** para **cargar, procesar y visualizar las imÃ¡genes** almacenadas en el CSV. ğŸ“ŠğŸ–¼ï¸  

---

## ğŸ› ï¸ **Â¿QuÃ© hace cada mÃ³dulo?**  

1ï¸âƒ£ **`pandas` â†’ Manejo de Datos Tabulares** ğŸ“Š  
   - `import pandas as pd`  
   - Permite **cargar el CSV** y trabajar con Ã©l como un **DataFrame**.  
   - Se usarÃ¡ para leer y verificar la estructura de los datos.  

2ï¸âƒ£ **`matplotlib.pyplot` â†’ VisualizaciÃ³n de Datos** ğŸ“ˆ  
   - `import matplotlib.pyplot as plt`  
   - Nos permite **mostrar las imÃ¡genes** contenidas en el CSV.  
   - Se usarÃ¡ para graficar y confirmar que las imÃ¡genes se han guardado correctamente.  

3ï¸âƒ£ **`base64` â†’ DecodificaciÃ³n de ImÃ¡genes** ğŸ”„  
   - `import base64`  
   - Convierte las imÃ¡genes **de Base64 a un formato visualizable**.  
   - Se usarÃ¡ para reconstruir las imÃ¡genes almacenadas en el CSV.  

4ï¸âƒ£ **`BytesIO` â†’ Manejo de Archivos en Memoria** ğŸ’¾  
   - `from io import BytesIO`  
   - Permite trabajar con **imÃ¡genes sin necesidad de guardarlas en disco**.  
   - Se usarÃ¡ para cargar imÃ¡genes directamente en memoria antes de visualizarlas.  

5ï¸âƒ£ **`PIL.Image` â†’ Procesamiento de ImÃ¡genes** ğŸ–¼ï¸  
   - `from PIL import Image`  
   - Nos permite **abrir, procesar y mostrar imÃ¡genes** en Python.  
   - Se usarÃ¡ para reconstruir las imÃ¡genes en Base64 y mostrarlas en pantalla.  

---

<img src="Imagenes/VisualizaciÃ³n_de_datos/imagen-2.png" width="600" height="300">

# ğŸ“„ **Lectura y ExtracciÃ³n de ImÃ¡genes desde CSV**  

En este paso, **cargamos el archivo CSV y extraemos la primera imagen** almacenada en formato Base64 para verificar su correcta codificaciÃ³n. ğŸ“‚ğŸ–¼ï¸  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Carga el archivo CSV** ğŸ“„  
   - `df = pd.read_csv('chair.csv')`  
   - **Lee el archivo `chair.csv`** usando Pandas y lo almacena en un **DataFrame**.  
   - Contiene la columna `"chair"` con imÃ¡genes en formato **Base64 dentro de etiquetas HTML**.  

2ï¸âƒ£ **Obtiene la primera fila del DataFrame** ğŸ”  
   - `first_row = df.iloc[0]`  
   - Usa `.iloc[0]` para **seleccionar la primera fila** del DataFrame.  
   - Se extrae una imagen **para verificar que los datos estÃ¡n bien guardados**.  

3ï¸âƒ£ **Extrae la imagen en Base64** ğŸ—ï¸  
   - `img_base64 = first_row['chair']`  
   - Se accede a la columna `"chair"` de la primera fila.  
   - **AquÃ­ se encuentra el cÃ³digo Base64 dentro de una etiqueta HTML**.  

---


<img src="Imagenes/VisualizaciÃ³n_de_datos/imagen-3.png" width="600" height="300">


# ğŸ–¼ï¸ **VerificaciÃ³n, DecodificaciÃ³n y VisualizaciÃ³n de la Imagen**  

Este cÃ³digo **verifica que la imagen en Base64 estÃ© en el formato correcto, la decodifica y la muestra en pantalla**. ğŸ“‚ğŸ”  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona?**  

1ï¸âƒ£ **Verifica si la cadena Base64 tiene un prefijo de datos** ğŸ”  
   - `if ',' in img_base64:`  
   - Algunas imÃ¡genes en Base64 **pueden incluir un prefijo**, por ejemplo:  
     ```
     data:image/png;base64,iVBORw...
     ```
   - Si hay una coma `,`, significa que el prefijo estÃ¡ presente.  
   - `img_base64.split(',')[1]` extrae **solo la parte Base64**, eliminando `"data:image/png;base64,"`.  

2ï¸âƒ£ **Asegura que la longitud de la cadena sea un mÃºltiplo de 4** ğŸ”¢  
   - `padding = len(img_base64) % 4`  
   - Base64 **debe tener una longitud en mÃºltiplos de 4**.  
   - Si no lo es, **se agregan los caracteres `=` necesarios** para corregir la cadena.  
   - `img_base64 += '=' * (4 - padding)` **corrige la longitud si es necesario**.  

3ï¸âƒ£ **Intenta decodificar la imagen** ğŸ—ï¸  
   - `img_data = base64.b64decode(img_base64)`  
   - Convierte la cadena **de Base64 a datos binarios de imagen**.  

4ï¸âƒ£ **Convierte los datos en una imagen visualizable** ğŸ–¼ï¸  
   - `img = Image.open(BytesIO(img_data))`  
   - Usa `BytesIO` para **convertir los datos binarios en una imagen sin guardarla en disco**.  
   - `Image.open()` abre la imagen lista para ser visualizada.  

5ï¸âƒ£ **Muestra la imagen** ğŸ“Š  
   - `plt.figure()` â†’ Crea una nueva figura para la imagen.  
   - `plt.imshow(img)` â†’ Muestra la imagen decodificada.  
   - `plt.axis('off')` â†’ Oculta los ejes para mejorar la visualizaciÃ³n.  
   - `plt.show()` â†’ Muestra la imagen en pantalla.  

6ï¸âƒ£ **Manejo de errores** âš ï¸  
   - Si ocurre un error en la decodificaciÃ³n, se captura con `except Exception as e`.  
   - Se imprime un mensaje de error con `print(f"Error al decodificar la imagen: {e}")`.  

---

<img src="Imagenes/VisualizaciÃ³n_de_datos/imagen-4.png" width="600" height="300"> 

# ğŸ–±ï¸ **VerificaciÃ³n de Datos de Ratones**  

Ahora que hemos extraÃ­do y almacenado los datos, **vamos a verificar su integridad** antes de proceder con la visualizaciÃ³n en Power BI. ğŸ“Š  

---

## ğŸ› ï¸ **Â¿CÃ³mo funciona esta prueba?**  

1ï¸âƒ£ **Carga el archivo CSV** ğŸ“‚  
   - `df_datos = pd.read_csv('/content/ratones_p1.csv')`  
   - Usa Pandas para **leer los datos almacenados en el archivo CSV**.  

2ï¸âƒ£ **Muestra las primeras filas** ğŸ”  
   - `print(df_datos.head())`  
   - Permite visualizar las primeras 5 filas del dataset para asegurarnos de que los datos estÃ¡n bien organizados.  

3ï¸âƒ£ **Cuenta los valores nulos por columna** ğŸ”¢  
   - `print(df_datos.isna().sum())`  
   - Muestra **cuÃ¡ntos valores nulos hay en cada columna**, ayudando a identificar posibles problemas en los datos.  

---

## ğŸ“Š **VisualizaciÃ³n de Datos en Power BI**  

Una vez que hemos procesado y comprobado de que no tiene **null** en ninguna fila, el siguiente paso es **visualizarlos en Power BI** para analizarlos de manera mÃ¡s intuitiva. ğŸ“ˆâœ¨  

![image](/API_InnerVisionAI/Imagenes/Power%20Bi/2025-03-03%2008_56_15-Inervision.png)

Para visualizar el Power Bi de manera interactiva aqui. **Nota** : Es importante tener cuenta de power BI para poder acceder. 

## 5. PreparaciÃ³n de los datos para los algoritmos de Machine Learning. Se deben tratar los datos (limpiando, escalando, separando y todo lo que sea necesario) de tal forma que queden listos para entrenar el modelo.
### 5.1 Proceso de Fine-Tuning con YOLOv5

El objetivo del fine-tuning es adaptar un modelo preentrenado de YOLOv5 (yolov5nu.pt) a nuestro dataset, mejorando su capacidad de detecciÃ³n en nuestro caso de uso especÃ­fico.

### ğŸ“‚ 5.1.1 PreparaciÃ³n del Dataset
Para entrenar el modelo, primero preparamos los datos siguiendo los pasos detallados a continuaciÃ³n:

1ï¸âƒ£ ObtenciÃ³n del Dataset

Realizamos scraping de imÃ¡genes, almacenÃ¡ndolas en un archivo CSV en formato base64.

ğŸ“Œ Ejemplo de archivo:
![image](https://github.com/user-attachments/assets/6803008a-0ca4-4ad6-830b-18efb486ba31)

---

2ï¸âƒ£ ConversiÃ³n de ImÃ¡genes

Como las imÃ¡genes estaban almacenadas en formato base64, era necesario decodificarlas para poder usarlas en el entrenamiento.

Utilizamos el siguiente script en Python para convertir las imÃ¡genes de base64 a `.jpg`:

![image](https://github.com/user-attachments/assets/58af828c-a9dc-40a4-9005-2d6db3b7bb56)

---

3ï¸âƒ£ Etiquetado de ImÃ¡genes

Para entrenar un modelo de detecciÃ³n de objetos, cada imagen necesita etiquetas con las coordenadas de los objetos. Utilizamos **Roboflow**, una plataforma que permite:

- âœ… Subir imÃ¡genes.
- âœ… Etiquetar imÃ¡genes manualmente o automÃ¡ticamente con herramientas de anotaciÃ³n.
- âœ… Convertir el dataset a formatos compatibles con modelos de detecciÃ³n como YOLOv5.
- âœ… Dividir los datos en conjuntos de entrenamiento, validaciÃ³n y prueba.

Nuestro objetivo fue **etiquetar automÃ¡ticamente** imÃ¡genes del dataset para detectar objetos de interÃ©s y exportarlas en formato YOLOv5.

ğŸ”¹ CreaciÃ³n de un Proyecto en Roboflow

- Asignamos un nombre al proyecto, por ejemplo: cupboard_detection.
- Seleccionamos el tipo de modelo: Object Detection (YOLOv5, COCO, etc.)

![image](https://github.com/user-attachments/assets/6ad1ed78-265d-44b6-8ecb-ff13b256031b)
  

ğŸ”¹ Subida de ImÃ¡genes al Proyecto

![image](https://github.com/user-attachments/assets/5c00338e-e366-49b7-b870-caab13064313)

ğŸ”¹ Etiquetado AutomÃ¡tico de Objetos

Dado que Roboflow cuenta con herramientas de etiquetado automÃ¡tico, utilizamos esta opciÃ³n para generar anotaciones sin intervenciÃ³n manual.

![image](https://github.com/user-attachments/assets/65260858-f3dd-4f6e-b690-78e095ef2e20)

Si bien el etiquetado automÃ¡tico es preciso, verificamos que las anotaciones fueran correctas.

![image](https://github.com/user-attachments/assets/b50e683b-e12b-4f62-906e-a672ed6310d8)

En caso de errores, ajustamos manualmente las etiquetas antes de continuar para completar el proceso.

![image](https://github.com/user-attachments/assets/ebea7738-f6de-4def-853f-dd361ac78e29)

DespuÃ©s de la comprobaciÃ³n aÃ±adimos las etiquetas aprobadas.

![image](https://github.com/user-attachments/assets/faf2c310-4d9d-47ba-8a08-9e818f91ae73)



ğŸ”¹ ExportaciÃ³n del Dataset en Formato YOLOv5

Para utilizar las imÃ¡genes etiquetadas en el entrenamiento del modelo, exportamos el dataset en formato YOLOv5.

Roboflow nos permite dividir el dataset en tres subconjuntos:
- 80% para entrenamiento (train)
- 10% para validaciÃ³n (valid)
- 10% para prueba (test)

![image](https://github.com/user-attachments/assets/9a021657-f59a-4b1c-bac5-f258790e0bf2)

En la secciÃ³n de exportaciÃ³n, seleccionamos YOLOv5 como formato de salida y descargamos un archivo ZIP.

![image](https://github.com/user-attachments/assets/a4fd3ee4-1efb-4581-8b08-c9d18a9aefb9)

El archivo ZIP tiene la siguiente estructura:

```
/dataset
â”‚â”€â”€ test/    # 10% de imÃ¡genes para prueba
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ labels/   
â”‚
â”‚â”€â”€ train/   # 80% de imÃ¡genes para entrenamiento
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ labels/
|
â”‚â”€â”€ valid/   # 10% de imÃ¡genes para validaciÃ³n
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ labels/
â”‚
â”‚â”€â”€ data.yaml    # Archivo de configuraciÃ³n del dataset
```

En el directorio `labels` obtenemos archivos .txt con las coordenadas de los objetos.


### ğŸ›  5.1.2 Entrenamiento del Modelo

Para el entrenamiento utilizamos el modelo preentrenado **yolov5nu.pt**. Ejecutamos el proceso en Google Colab con GPU habilitada para acelerar el cÃ³mputo. Clonamos el repositorio de YOLOv5. Usamos los siguientes parÃ¡metros en el script de entrenamiento:

```python
!python train.py \
  --weights /content/drive/MyDrive/Models/yolov5nu.pt \
  --data /content/drive/MyDrive/YOLO_Dataset/data.yaml \
  --epochs 50 \
  --batch-size 16 \
  --imgsz 640 \
  --optimizer SGD \
  --device 0
```

Sin embargo, durante la ejecuciÃ³n del entrenamiento encontramos errores relacionados con la configuraciÃ³n de los anchors en el modelo. El siguiente es un ejemplo de los errores que recibimos:

```
RuntimeError: shape '[3, -1, 2]' is invalid for input of size 3
```

Este error sugiere que los anchors definidos en el modelo no se ajustaban correctamente al nÃºmero de clases u otras dimensiones esperadas. Intentamos modificar la configuraciÃ³n, pero el problema persistiÃ³.

---

âš ï¸ Problemas Encontrados y ConclusiÃ³n

No logramos completar el fine-tuning debido a erroresencontrados. Las posibles causas incluyen:

1. **Incompatibilidad en los anchors**: La configuraciÃ³n de los anchors puede no haber sido adecuada para nuestro dataset. 
2. **Formato incorrecto en el archivo data.yaml**: Es posible que las clases o los parÃ¡metros en el archivo no estuvieran correctamente definidos.
3. **Modelo preentrenado incompatible**: Puede que el modelo **yolov5nu.pt** no estuviera configurado correctamente para ser reutilizado con nuevos datos.

Para solucionar estos problemas, proponemos:
- Revisar el formato de **data.yaml** y asegurarnos de que estÃ¡ bien definido.
- Ajustar los anchors manualmente o permitir que YOLO los recalibre automÃ¡ticamente.
- Probar con otro modelo preentrenado de YOLOv5 para verificar compatibilidad.

A pesar de las dificultades, este proceso nos permitiÃ³ comprender mejor el flujo de trabajo de YOLOv5 y los retos asociados a la personalizaciÃ³n de modelos de detecciÃ³n de objetos. Con algunos ajustes, creemos que podemos completar con Ã©xito el fine-tuning en futuras iteraciones.


## 6. Entrenamiento del modelo y comprobaciÃ³n del rendimiento. Se entrenarÃ¡n uno o varios modelos, comprobando en cada caso el rendimiento que ofrecen mediante las apropiadas medidas de error y/o acierto.

### 6.1 Uso de YOLOv5 de Ultralytics y Chatbot personalizado

En este apartado, se describe el proceso de implementaciÃ³n de YOLOv5 de Ultralytics, desde la configuraciÃ³n del entorno hasta la integraciÃ³n con una API en Flask y un frontend en React. El objetivo es demostrar cÃ³mo este modelo puede ser utilizado para detectar objetos en tiempo real, enviando los resultados de las detecciones a una interfaz grÃ¡fica que permite visualizar las predicciones de manera intuitiva. 
AdemÃ¡s, se aborda la importancia de optimizar el flujo de trabajo para garantizar un rendimiento Ã³ptimo, especialmente como tratar el funcionamiento con recursos gratuitos y el limite que establece Netlify y nuestra API con Flask en local.

TambiÃ©n ideamos un chatbot con una API-KEY de OpenAI, donde con base en nuestro README.md, procese y responda preguntas y cuestiones sobre nuestro proyecto debido a, que nuestro readme va a ser bastante extenso.

Primero explicaremos el funcionamiento de YOLOv5 con Ultralytics.

#### Uso de la API con Flask

La API desarrollada con Flask sirve como el nÃºcleo del proyecto, facilitando la comunicaciÃ³n entre el modelo de detecciÃ³n de objetos YOLOv5 y el chatbot basado en OpenAI. Esta API maneja tanto el procesamiento de imÃ¡genes en tiempo real mediante WebSockets como la interacciÃ³n con el chatbot mediante solicitudes REST.

#### ConfiguraciÃ³n del Entorno

Antes de ejecutar la API, es necesario asegurarse de que se tienen instaladas todas las dependencias necesarias. Se pueden instalar mediante:

```bash
pip install -r requirements.txt
python app.py
```

(Aconsejable hacer un environment si necesitas versiones especÃ­fica)

Como la versiÃ³n de Python que usamos era la 3.10, con ejecutar el comando de arriba, te instalarÃ¡ siempre lo Ãºltimo de esta versiÃ³n en concreto de python.

#### Uso de WebSocket para DetecciÃ³n de Objetos con YOLOv5

La API emplea flask_socketio para recibir imÃ¡genes desde el frontend en tiempo real, procesarlas con YOLOv5 y devolver las detecciones correspondientes.

#### Flujo de Trabajo

- El frontend envÃ­a frames codificados en base64 mediante WebSocket.

- La API recibe y decodifica la imagen, luego la redimensiona para mejorar la eficiencia.

- YOLOv5 procesa la imagen y genera predicciones sobre los objetos detectados.

- La API envÃ­a las detecciones de vuelta al frontend a travÃ©s de WebSocket.

![api_websocket](https://github.com/user-attachments/assets/0be421ff-2753-4eea-8bb0-560b6aa6c703)

Aunque la anterior imagen representa la funciÃ³n y puede ser engorrosa, la siguiente captura serÃ¡ la zona importante y vital de entender.
Esta parte es la mÃ¡s importante ya que sin ella, no podrÃ­amos representar en el frontend mediante el uso de canvas, pintar los rectÃ¡ngulos de la detecciÃ³n de objetos ya que nos da:
- Las posiciones de cada objeto
- Redonde el score del objeto a 2 decimales
- Gracias a la id, accedemos al nombre de la clase, por ejemplo, 0 - Persona
- AÃ±adimos esto a una lista finalmente
  
![api_socket2](https://github.com/user-attachments/assets/fe737556-a178-4f62-af07-5f0f63d33886)

#### Uso de API REST para el Chatbot Personalizado

Para permitir que los usuarios interactÃºen con el chatbot, la API implementa un endpoint /chat que recibe preguntas del usuario y responde basÃ¡ndose en el contenido del README.md del proyecto.

#### Flujo de Trabajo

- El usuario envÃ­a una solicitud POST a /chat con el mensaje en formato JSON.

- La API obtiene el contenido del README.md desde GitHub.

- Se construye un mensaje para OpenAI combinando la pregunta del usuario y la informaciÃ³n del README.md.

- La API envÃ­a la solicitud a OpenAI y devuelve la respuesta generada.

La parte del frontend serÃ¡ expuesta en la secciÃ³n **8. Desarrollo de la AplicaciÃ³n Web**

![api_rest](https://github.com/user-attachments/assets/1045acd4-a22b-44f2-ae54-376e16ca642e)

Vemos aquÃ­ mas directamente la parte importante, que usarÃ¡ el rol de system, con lo cual nos permite generar un prompt anterior al promt del usuario, donde gracias a esta funciÃ³n, transformamos el readme...
![readme](https://github.com/user-attachments/assets/fc3a12d0-7bfc-4919-8424-545b98158e73)

Para conseguir asÃ­ finalmente que "sesgemos" al modelo para que responda preguntas con base en nuestro Readme.
![api_chat2](https://github.com/user-attachments/assets/b0b03eec-27d0-43eb-b092-d6e35d641c51)

Las demÃ¡s lineas de cÃ³digo son necesarias para permisos y utilidad como:

**CORS**
![cors1](https://github.com/user-attachments/assets/8f0fc1bd-7060-4089-80d7-5c7b572813e0)
![cors2](https://github.com/user-attachments/assets/cd79b6b5-5ae4-402f-9195-57947fed27bf)

**OptimizaciÃ³n YOLO**
![yolo1](https://github.com/user-attachments/assets/15184317-f9f6-4be5-ab08-e465cf3b873e)

---

## 7. Se tiene que incluir alguna de las tÃ©cnicas estudiadas en el tema de Procesamiento de Lenguaje Natural: expresiones regulares, tokenizaciÃ³n, generaciÃ³n de texto, anÃ¡lisis de sentimientos, etc.

En el proyecto hemos integrado diversas tÃ©cnicas de **Procesamiento de Lenguaje Natural (PLN)** para mejorar la interacciÃ³n con el usuario y optimizar el anÃ¡lisis de texto.

### 7.1. Uso de Expresiones Regulares en el Formateo de Respuestas del Chatbot

En la pÃ¡gina de `Chatbot.tsx` hemos desarrollado una funciÃ³n llamada `formatResponse()`, cuya finalidad es mejorar la legibilidad de los mensajes del chatbot al usuario. Para ello, aplicamos **expresiones regulares** que permiten transformar ciertos patrones de texto en formato HTML.

ğŸ“Œ CÃ³digo de la funciÃ³n:
![image](https://github.com/user-attachments/assets/3077c79d-38dd-4a5d-8cc7-6e688da97c0c)

Desglose del cÃ³digo:

1ï¸âƒ£ `replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')`:

- Busca cualquier texto encerrado entre `**` y lo reemplaza por `<strong>`, convirtiÃ©ndolo en negrita.
- Ejemplo: `"Este es un **mensaje importante**"` â†’ `"Este es un <strong>mensaje importante</strong>"`.

2ï¸âƒ£ `replace(/\n/g, '<br>')`:

- Reemplaza los saltos de lÃ­nea (`\n`) por etiquetas HTML `<br>`, asegurando que el texto respete los espacios entre lÃ­neas.
- Ejemplo: `"LÃ­nea 1\nLÃ­nea 2"` â†’ `"LÃ­nea 1<br>LÃ­nea 2"`.

3ï¸âƒ£ `replace(/\d+\. /g, '<br>â€¢ ')`:

- Busca listas numeradas (`1. Texto`, `2. Texto`, etc.) y las convierte en listas con viÃ±etas (`â€¢ Texto`).
- Ejemplo:
  
```plaintext
1. Manzana
2. Pera
```
Se transformarÃ¡ en:
```html
Copiar
Editar
<br>â€¢ Manzana
<br>â€¢ Pera
```

## 8. Desarrollo de la AplicaciÃ³n Web

Nuestra aplicaciÃ³n web ha sido desarrollada utilizando **React** e **Ionic** con **TypeScript**, proporcionando una experiencia moderna y responsiva. A continuaciÃ³n, describimos los principales componentes de la web junto con capturas del cÃ³digo y la interfaz.

### 8.1 Estructura del Proyecto

El proyecto se organiza en distintos componentes de React y pÃ¡ginas especÃ­ficas para cada funcionalidad. Nuestra estructura principal incluye:
- **Home.tsx** (PÃ¡gina de inicio)
- **Model.tsx** (MÃ³dulo de detecciÃ³n de objetos)
- **AboutUs.tsx** (InformaciÃ³n del equipo)
- **Chatbot.tsx** (Asistente virtual basado en IA)

Con esta organizaciÃ³n permitimos una estructura modular y escalable. ğŸš€

### 8.2 Inicio (Home.tsx)

Nuestra pÃ¡gina principal (**Home.tsx**) presenta el proyecto y enlaza a su repositorio en GitHub. Hemos utilizado iconos para mejorar la accesibilidad visual.

#### Â¿QuÃ© hace este archivo?
- Muestra el diseÃ±o principal: Incluimos el encabezado, el contenido y cualquier elemento visual que queramos resaltar.
- Carga datos si es necesario: Dependiendo de lo que queremos mostrar, aquÃ­ podemos traer informaciÃ³n desde una API o una base de datos.
- Facilita la navegaciÃ³n: Agregamos enlaces o botones para que los usuarios puedan moverse dentro de nuestra aplicaciÃ³n.
  
---

#### 8.2.1 ImportaciÃ³n de librerÃ­as y estilos
El archivo `Home.tsx` es un componente de React que utiliza Ionic y otros elementos para la estructura y diseÃ±o de la pantalla principal de la aplicaciÃ³n.

ğŸ“Œ CÃ³digo de importaciÃ³n:
![image](https://github.com/user-attachments/assets/b3ce7a56-9c89-4614-93ee-706c37b11121)

---

#### 8.2.2 Contenido de la pÃ¡gina
En la secciÃ³n principal de la pantalla, mostramos el tÃ­tulo del proyecto junto con una breve descripciÃ³n para que los usuarios comprendan su propÃ³sito de inmediato. AdemÃ¡s, proporcionamos enlaces directos a los repositorios de GitHub, tanto para la web como para la API, con iconos interactivos que facilitan el acceso.

ğŸ“Œ CÃ³digo del contenido:
![image](https://github.com/user-attachments/assets/1d891c5d-278b-42b3-8b11-5adc13391e66)

---

#### 8.2.3 Estilos Aplicados
En `Home.css`, definimos estilos para mejorar la apariencia del componente. 

ğŸ“Œ Ejemplo de diseÃ±o:

![image](https://github.com/user-attachments/assets/2b9051a9-4ea8-4f39-bdbf-de611e44f181)

Con estos estilos nos aseguramos que la pÃ¡gina tenga un diseÃ±o centrado y estÃ©tico.


âœ¨ **Vista de la pÃ¡gina de inicio:**  

![image](https://github.com/user-attachments/assets/a850f36f-605a-406a-a75b-50b4e671ce34)


Esta pÃ¡gina brinda una bienvenida clara y acceso directo a la informaciÃ³n clave del proyecto. ğŸš€

## 8.3 Modelo de DetecciÃ³n de Objetos (Model.tsx)

En esta pÃ¡gina implementamos la detecciÃ³n de objetos en tiempo real utilizando la cÃ¡mara del dispositivo. Para ello, hacemos uso de WebSockets para enviar frames al backend y recibir las detecciones procesadas.

#### Â¿QuÃ© hace este archivo?
- Captura video en tiempo real desde la cÃ¡mara del dispositivo. El cÃ³digo a continuaciÃ³n solicita permisos para acceder a la cÃ¡mara del dispositivo y captura el video en tiempo real:
  
  ![image](https://github.com/user-attachments/assets/9d704801-afd2-4f15-8cb7-8563a47fdeb5)

- EnvÃ­a frames al backend. Usa WebSockets para enviar imÃ¡genes a la API, donde se realiza la detecciÃ³n de objetos.

  ![image](https://github.com/user-attachments/assets/3045fff8-ff73-4c49-b901-24192edad290)

  
- Recibe y dibuja detecciones. Recibe los resultados del backend y los dibuja sobre el video en un canvas.

  ![image](https://github.com/user-attachments/assets/aa6c6931-02fe-444d-83f4-0db89417b673)

---

#### 8.3.1 ImportaciÃ³n de librerÃ­as y estilos
El archivo Model.tsx importa las siguientes librerÃ­as:

- react, useEffect, useRef: Para gestionar el ciclo de vida del componente y referencias.
- socket.io-client: Para la comunicaciÃ³n en tiempo real con el backend.
- @ionic/react: Para la estructura de la pÃ¡gina en Ionic.
- @capacitor/core y @capacitor/status-bar: Para ajustar la interfaz en dispositivos mÃ³viles.

ğŸ“Œ CÃ³digo de importaciÃ³n:
![image](https://github.com/user-attachments/assets/44c13030-c11c-450b-8eff-bf19317438da)

---

#### 8.3.2 Contenido de la pÃ¡gina
Esta secciÃ³n estructura la interfaz del mÃ³dulo:

- Video en vivo: Capturamos la imagen de la cÃ¡mara.
- Canvas de detecciones: Dibujamos los resultados del modelo de IA sobre el video.

ğŸ“Œ CÃ³digo del contenido:
![image](https://github.com/user-attachments/assets/a9428b16-d8ba-474a-9211-cdd2a1f4d686)

---

#### 8.3.3 ComunicaciÃ³n con el Backend

ConexiÃ³n al Backend (A nivel local)
![image](https://github.com/user-attachments/assets/9f55390b-f505-409d-a544-9972425c4e85)

AquÃ­ se establece la conexiÃ³n con el backend en el puerto 5000.

Cuando el backend detecta objetos en el frame enviado, devuelve las coordenadas y la confianza del modelo. Este cÃ³digo se encarga de dibujar los resultados sobre el video:

![image](https://github.com/user-attachments/assets/61bd5e5d-8bb5-4451-8c40-a219badb81d9)

Desconecta el socket cuando el usuario sale de la pÃ¡gina:

![image](https://github.com/user-attachments/assets/c6493fce-0297-4b97-a311-39f34df48f0a)

---

#### 8.3.4 Estilos Aplicados
En Model.css, definimos estilos para:

Centrar el video en pantalla.
Ajustar el tamaÃ±o del video y el canvas.
Aplicar un fondo con degradado.

ğŸ“Œ Ejemplo de diseÃ±o:
![image](https://github.com/user-attachments/assets/c44fcc65-8273-48ec-b1da-ffd645ccf3e7)


âœ¨ **Vista del modelo de detecciÃ³n de objetos:**

[Imagen del modelo funcionando]

Con esta implementaciÃ³n logramos un procesamiento Ã¡gil y preciso, permitiendo a los usuarios identificar objetos en tiempo real de manera intuitiva y eficaz. ğŸ¯

## 8.4 InformaciÃ³n del Equipo (AboutUs.tsx)

En esta pÃ¡gina mostramos a los integrantes del equipo de desarrollo. En la pÃ¡gina se puede visualizar una lista de miembros, su rol, su formaciÃ³n y enlaces a sus perfiles de GitHub y LinkedIn.

âœ¨ **Vista de la pÃ¡gina de InformaciÃ³n del Equipo:**

![image](https://github.com/user-attachments/assets/e2236a86-5f5f-44dc-82c4-b8aa7872afaa)


## 8.5 Chatbot (Chatbot.tsx)

En esta pÃ¡gina implementamos un chatbot interactivo que permite a los usuarios realizar preguntas. Utilizamos un backend en Node.js para procesar las consultas y devolver respuestas dinÃ¡micas.

### Â¿QuÃ© hace este archivo?
- **Muestra un chatbot en la aplicaciÃ³n.**
- **Permite la interacciÃ³n con el usuario.** El usuario puede escribir preguntas y recibir respuestas en tiempo real.
- **EnvÃ­a consultas a un backend en Node.js.** Se conecta a un servidor en `http://localhost:5000/chat` para procesar los mensajes.
- **Formatea las respuestas.** Convierte ciertos elementos de texto como negritas y listas en formato HTML para mejorar la legibilidad.

---

### 8.5.1 ImportaciÃ³n de librerÃ­as y estilos
El archivo `Chatbot.tsx` importa las siguientes librerÃ­as:

- **react, useState**: Para gestionar el estado del chatbot y los mensajes.
- **axios**: Para enviar solicitudes HTTP al backend.
- **@ionic/react**: Para la estructura de la pÃ¡gina.
- **Footer**: Componente reutilizable para el pie de pÃ¡gina.
- **Chatbot.css**: Archivo de estilos para la apariencia del chatbot.

ğŸ“Œ **CÃ³digo de importaciÃ³n:**
![image](https://github.com/user-attachments/assets/8822090b-325f-4af6-aa1f-72307de3ce1f)


### 8.5.2 Estado y manejo de mensajes
Almacenamos los mensajes en un array gestionado con `useState`. Inicialmente, contiene un mensaje de bienvenida del bot:

ğŸ“Œ **CÃ³digo de inicializaciÃ³n:**
![image](https://github.com/user-attachments/assets/bf0786c2-d521-4084-a8a0-e469a4a0aa52)
![image](https://github.com/user-attachments/assets/59699bd8-f7bf-437c-bffb-d92c8e92b76d)


El usuario puede escribir un mensaje y enviarlo con `sendMessage()`, que realiza las siguientes acciones:
1. Agrega el mensaje del usuario al estado.
2. EnvÃ­a la consulta al backend mediante una peticiÃ³n `POST`.
3. Recibe la respuesta del servidor y la formatea.
4. Agrega la respuesta del chatbot a la conversaciÃ³n.
5. Limpia el input despuÃ©s de enviar el mensaje.

ğŸ“Œ **CÃ³digo de envÃ­o de mensajes:**
![image](https://github.com/user-attachments/assets/f6eabbe7-1417-42dd-88b0-25fa0b26bf11)


---

### 8.5.3 Renderizado del Chatbot

El chatbot se compone de:
- Un **contenedor de mensajes**, donde se muestran las interacciones previas.
- Un **input de texto** para que el usuario escriba su mensaje.
- Un **botÃ³n de envÃ­o** para enviar mensajes manualmente.
- La posibilidad de presionar **Enter** para enviar el mensaje.

ğŸ“Œ **CÃ³digo del renderizado:**
![image](https://github.com/user-attachments/assets/ef0402ba-5a17-42e8-8ef4-591904aab9c8)


---

### 8.5.4 Formateo de respuestas

Para mejorar la presentaciÃ³n de las respuestas, convertimos ciertos elementos a formato HTML:
- **Negritas**: `**texto**` â†’ `<strong>texto</strong>`
- **Saltos de lÃ­nea**: `\n` â†’ `<br>`
- **Listas numeradas**: `1. Texto` â†’ `â€¢ Texto`

ğŸ“Œ **CÃ³digo de formateo:**
![image](https://github.com/user-attachments/assets/ac19de25-1edd-4c50-b5e9-ac02fcf076a0)



---

âœ¨ **Vista del chatbot funcionando:**

![chatbot](https://github.com/user-attachments/assets/915472c2-ab6a-485f-ac20-7fb3b2ff22d0)

Con esta implementaciÃ³n ofrecemos una experiencia fluida y responsiva, permitiendo a los usuarios interactuar con el asistente virtual de manera sencilla y eficiente. ğŸš€


## 9. Conclusiones. Se expondrÃ¡n las conclusiones que se han obtenido en la realizaciÃ³n del TFM.
